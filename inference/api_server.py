#!/usr/bin/env python3
"""
ç‹¬ç«‹çš„æ¨ç†APIæœåŠ¡å™¨
ç«¯å£: 5006
åŠŸèƒ½: æä¾›æµå¼æ¨ç†æœåŠ¡ï¼Œè°ƒç”¨vLLMæœåŠ¡å™¨è¿›è¡Œæ·±åº¦ç ”ç©¶
"""

import os
import json
import asyncio
import uuid
import logging
from typing import Dict, Generator, Optional
from datetime import datetime
from fastapi import FastAPI, HTTPException
from fastapi.responses import StreamingResponse, JSONResponse
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import uvicorn
import threading

from streaming_agent import StreamingReactAgent

# é…ç½®æ—¥å¿—
log_level = os.getenv('LOG_LEVEL', 'INFO').upper()
log_level_value = getattr(logging, log_level, logging.INFO)

# é…ç½®æ ¹æ—¥å¿—è®°å½•å™¨
logging.basicConfig(
    level=log_level_value,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S',
    force=True  # å¼ºåˆ¶é‡æ–°é…ç½®
)

# è®¾ç½®æ‰€æœ‰ç›¸å…³æ¨¡å—çš„æ—¥å¿—çº§åˆ«
for module_name in ['streaming_agent', 'answer_system', 'tool_retrieval', '__main__']:
    logging.getLogger(module_name).setLevel(log_level_value)

logger = logging.getLogger(__name__)
logger.info(f"æ—¥å¿—çº§åˆ«è®¾ç½®ä¸º: {log_level}")

# é…ç½®
API_PORT = int(os.getenv('API_PORT', 5006))

# LLM é…ç½®ï¼šä»ç¯å¢ƒå˜é‡è¯»å–
LLM_BASE_URL = os.getenv('LLM_BASE_URL', 'https://dashscope.aliyuncs.com/compatible-mode/v1')
LLM_API_KEY = os.getenv('LLM_API_KEY', 'your-api-key-here')
LLM_MODEL = os.getenv('LLM_MODEL', 'qwen3-max')

# å…¼å®¹æ—§çš„ vLLM é…ç½®ï¼ˆå¦‚æœéœ€è¦æœ¬åœ°æ¨¡å‹ï¼‰
VLLM_PORT = int(os.getenv('PLANNING_PORTS', 6001))
MODEL_PATH = os.getenv('MODEL_PATH', LLM_MODEL)  # é»˜è®¤ä½¿ç”¨ LLM_MODEL

# å¹¶å‘æ§åˆ¶
MAX_CONCURRENT_REQUESTS = int(os.getenv('MAX_CONCURRENT_REQUESTS', 3))  # æœ€å¤§å¹¶å‘æ•°
processing_semaphore = threading.Semaphore(MAX_CONCURRENT_REQUESTS)  # ä¿¡å·é‡æ§åˆ¶å¹¶å‘
active_sessions = {}  # è·Ÿè¸ªæ´»è·ƒçš„ä¼šè¯
global_citations = {}  # å…¨å±€å­˜å‚¨æ‰€æœ‰ citations æ•°æ®ï¼ˆæŒ‰ citation_id ç´¢å¼•ï¼‰
session_lock = threading.Lock()  # ä»…ç”¨äºä¿æŠ¤active_sessionså’Œglobal_citationså­—å…¸

# ä¼šè¯å­˜å‚¨ï¼š{session_id: {"created_at": datetime, "messages": [{"role": "user/assistant", "content": "..."}]}}
chat_sessions = {}  # å­˜å‚¨æ‰€æœ‰ä¼šè¯çš„å†å²æ¶ˆæ¯

# åˆ›å»ºFastAPIåº”ç”¨
app = FastAPI(
    title="Tongyi DeepResearch API",
    description="æ·±åº¦ç ”ç©¶æ¨ç†APIæœåŠ¡",
    version="1.0.0"
)

# æ·»åŠ CORSä¸­é—´ä»¶
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# è¯·æ±‚æ¨¡å‹
class ChatRequest(BaseModel):
    question: str
    temperature: Optional[float] = 0.85
    top_p: Optional[float] = 0.95
    presence_penalty: Optional[float] = 1.1
    max_tokens: Optional[int] = 8000
    session_id: Optional[str] = None  # å¯é€‰çš„ä¼šè¯ID

class ChatResponse(BaseModel):
    type: str
    content: str
    timestamp: str
    round: Optional[int] = None
    tool_name: Optional[str] = None
    tool_args: Optional[Dict] = None
    result: Optional[str] = None
    code: Optional[str] = None

# å…¨å±€é…ç½®ï¼ˆæ¨¡æ¿ï¼‰
agent_config_template = None

def initialize_agent_config():
    """åˆå§‹åŒ–ä»£ç†é…ç½®æ¨¡æ¿"""
    global agent_config_template
    
    # é…ç½®LLMå‚æ•°æ¨¡æ¿
    agent_config_template = {
        "model": LLM_MODEL,
        "base_url": LLM_BASE_URL,
        "api_key": LLM_API_KEY,
        "generate_cfg": {
            "temperature": 0.85,
            "top_p": 0.95,
            "presence_penalty": 1.1,
            "max_tokens": 8000
        }
    }
    
    logger.info(f"âœ… æ¨ç†ä»£ç†é…ç½®æ¨¡æ¿åˆå§‹åŒ–å®Œæˆ")
    logger.info(f"ğŸ“¡ LLM APIåœ°å€: {LLM_BASE_URL}")
    logger.info(f"ğŸ¤– æ¨¡å‹: {LLM_MODEL}")
    logger.info(f"ğŸ”‘ API Key (masked): {LLM_API_KEY[:10]}...{LLM_API_KEY[-5:] if len(LLM_API_KEY) > 15 else ''}")

def create_agent_instance(temperature=0.85, top_p=0.95, presence_penalty=1.1, max_tokens=8000):
    """ä¸ºæ¯ä¸ªè¯·æ±‚åˆ›å»ºç‹¬ç«‹çš„agentå®ä¾‹"""
    import copy
    config = copy.deepcopy(agent_config_template)
    config["generate_cfg"].update({
        "temperature": temperature,
        "top_p": top_p,
        "presence_penalty": presence_penalty,
        "max_tokens": max_tokens
    })
    return StreamingReactAgent(llm=config)

@app.on_event("startup")
async def startup_event():
    """åº”ç”¨å¯åŠ¨æ—¶åˆå§‹åŒ–"""
    logger.info("ğŸš€ å¯åŠ¨Tongyi DeepResearch APIæœåŠ¡å™¨...")
    initialize_agent_config()
    logger.info(f"ğŸŒ APIæœåŠ¡å™¨å°†åœ¨ç«¯å£ {API_PORT} ä¸Šè¿è¡Œ")
    logger.info(f"ğŸ”’ å¹¶å‘æ§åˆ¶: æœ€å¤§å¹¶å‘è¯·æ±‚æ•° = {MAX_CONCURRENT_REQUESTS}")
    logger.info(f"ğŸ’¡ æç¤º: å¯é€šè¿‡ç¯å¢ƒå˜é‡ MAX_CONCURRENT_REQUESTS è°ƒæ•´å¹¶å‘æ•°")

@app.get("/")
async def root():
    """æ ¹è·¯å¾„"""
    return {
        "message": "Tongyi DeepResearch API Server",
        "version": "1.0.0",
        "status": "running",
        "vllm_port": VLLM_PORT,
        "model_path": MODEL_PATH
    }

@app.get("/health")
async def health_check():
    """å¥åº·æ£€æŸ¥"""
    available_slots = processing_semaphore._value  # å¯ç”¨æ§½ä½æ•°
    return {
        "status": "healthy",
        "timestamp": datetime.now().isoformat(),
        "agent_config_initialized": agent_config_template is not None,
        "active_sessions": len(active_sessions),
        "max_concurrent": MAX_CONCURRENT_REQUESTS,
        "available_slots": available_slots,
        "processing_count": MAX_CONCURRENT_REQUESTS - available_slots
    }

@app.get("/api/sessions/new")
async def create_new_chat_session():
    """åˆ›å»ºæ–°çš„èŠå¤©ä¼šè¯"""
    session_id = str(uuid.uuid4())
    created_at = datetime.now()
    
    with session_lock:
        chat_sessions[session_id] = {
            "created_at": created_at.isoformat(),
            "messages": []
        }
    
    logger.info(f"ğŸ“ åˆ›å»ºæ–°ä¼šè¯: {session_id[:8]}...")
    
    return {
        "session_id": session_id,
        "created_at": created_at.isoformat()
    }

@app.get("/api/sessions")
async def list_chat_sessions():
    """è·å–æ‰€æœ‰èŠå¤©ä¼šè¯åˆ—è¡¨ï¼ˆåŒ…å«å†å²æ¶ˆæ¯ç»Ÿè®¡ï¼‰"""
    with session_lock:
        sessions = [
            {
                "session_id": sid,
                "created_at": data["created_at"],
                "message_count": len(data["messages"])
            }
            for sid, data in chat_sessions.items()
        ]
        # æŒ‰åˆ›å»ºæ—¶é—´å€’åºæ’åˆ—ï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
        sessions.sort(key=lambda x: x["created_at"], reverse=True)
    
    return {
        "sessions": sessions,
        "total": len(sessions)
    }

@app.get("/api/sessions/{session_id}")
async def get_chat_session(session_id: str):
    """è·å–æŒ‡å®šèŠå¤©ä¼šè¯çš„è¯¦ç»†ä¿¡æ¯ï¼ˆåŒ…å«å®Œæ•´å†å²æ¶ˆæ¯ï¼‰"""
    with session_lock:
        if session_id not in chat_sessions:
            raise HTTPException(status_code=404, detail="ä¼šè¯ä¸å­˜åœ¨")
        
        session_data = chat_sessions[session_id]
    
    return {
        "session_id": session_id,
        "created_at": session_data["created_at"],
        "messages": session_data["messages"]
    }

@app.post("/chat/stream")
async def chat_stream(request: ChatRequest):
    """æµå¼èŠå¤©æ¥å£"""
    if agent_config_template is None:
        raise HTTPException(status_code=500, detail="æ¨ç†ä»£ç†é…ç½®æœªåˆå§‹åŒ–")
    
    # ç”Ÿæˆå”¯ä¸€çš„ä¼šè¯ID
    session_id = request.session_id or str(uuid.uuid4())
    
    try:
        def generate_stream():
            """ç”Ÿæˆæµå¼å“åº”"""
            agent = None
            acquired = False
            cancelled = {"value": False}  # å®¢æˆ·ç«¯æ–­å¼€æ ‡è®°ï¼ˆä½¿ç”¨å­—å…¸ä»¥ä¾¿ä¼ é€’å¼•ç”¨ï¼‰
            
            try:
                # è·å–ä¿¡å·é‡ï¼ˆå…è®¸æœ‰é™å¹¶å‘ï¼‰
                logger.info(f"â³ [Session {session_id[:8]}] ç­‰å¾…è·å–å¤„ç†æ§½ä½... (å½“å‰æ´»è·ƒ: {len(active_sessions)})")
                acquired = processing_semaphore.acquire(timeout=300)  # æœ€å¤šç­‰å¾…5åˆ†é’Ÿ
                
                if not acquired:
                    error_data = {
                        "type": "error",
                        "content": "æœåŠ¡å™¨ç¹å¿™ï¼Œè¯·æ±‚è¶…æ—¶ï¼Œè¯·ç¨åé‡è¯•",
                        "session_id": session_id,
                        "timestamp": datetime.now().isoformat()
                    }
                    yield f"data: {json.dumps(error_data, ensure_ascii=False)}\n\n"
                    
                    # å‘é€ completed äº‹ä»¶ä»¥ç¡®ä¿æµæ­£ç¡®å…³é—­
                    completed_data = {
                        "type": "completed",
                        "content": "è¯·æ±‚è¶…æ—¶ï¼Œæµç¨‹ç»“æŸ",
                        "session_id": session_id,
                        "timestamp": datetime.now().isoformat()
                    }
                    yield f"data: {json.dumps(completed_data, ensure_ascii=False)}\n\n"
                    return
                
                logger.info(f"ğŸš€ [Session {session_id[:8]}] è·å–æ§½ä½æˆåŠŸï¼Œå¼€å§‹å¤„ç†é—®é¢˜: {request.question[:50]}...")
                
                # ä¸ºè¿™ä¸ªè¯·æ±‚åˆ›å»ºç‹¬ç«‹çš„agentå®ä¾‹
                agent = create_agent_instance(
                    temperature=request.temperature,
                    top_p=request.top_p,
                    presence_penalty=request.presence_penalty,
                    max_tokens=request.max_tokens
                )
                
                # è®°å½•æ´»è·ƒä¼šè¯ï¼ˆä½¿ç”¨é”ä¿æŠ¤å­—å…¸æ“ä½œï¼‰
                with session_lock:
                    active_sessions[session_id] = {
                        "question": request.question,
                        "start_time": datetime.now().isoformat(),
                        "status": "processing",
                        "cancelled": cancelled  # ä¿å­˜å¼•ç”¨ï¼Œä¾¿äºå¤–éƒ¨æ£€æŸ¥
                    }
                
                # å‘é€ä¼šè¯å¼€å§‹äº‹ä»¶
                session_start_data = {
                    "type": "session_start",
                    "content": f"ä¼šè¯ {session_id[:8]} å¼€å§‹å¤„ç†",
                    "session_id": session_id,
                    "timestamp": datetime.now().isoformat()
                }
                yield f"data: {json.dumps(session_start_data, ensure_ascii=False)}\n\n"
                
                # åŠ è½½å†å²æ¶ˆæ¯
                history_messages = []
                with session_lock:
                    if session_id in chat_sessions:
                        history_messages = chat_sessions[session_id].get("messages", [])
                        logger.info(f"ğŸ“š [Session {session_id[:8]}] åŠ è½½äº† {len(history_messages)} æ¡å†å²æ¶ˆæ¯")
                    else:
                        # å¦‚æœä¼šè¯ä¸å­˜åœ¨ï¼Œåˆ›å»ºä¸€ä¸ªæ–°çš„
                        chat_sessions[session_id] = {
                            "created_at": datetime.now().isoformat(),
                            "messages": []
                        }
                
                # æ‰§è¡Œæµå¼å¤„ç†ï¼ˆä¼ å…¥ cancelled æ ‡è®°å’Œå†å²æ¶ˆæ¯ï¼‰
                has_completed = False  # æ ‡è®°æ˜¯å¦å·²å‘é€ completed äº‹ä»¶
                final_answer_content = ""  # ç”¨äºä¿å­˜æœ€ç»ˆç­”æ¡ˆï¼ˆä¸å«å‚è€ƒæ–‡çŒ®ï¼‰
                
                event_count = 0
                for event in agent.stream_run(request.question, cancelled=cancelled, history_messages=history_messages):
                    event_count += 1
                    
                    # æ¯ä¸ªäº‹ä»¶å‰æ£€æŸ¥å®¢æˆ·ç«¯æ˜¯å¦æ–­å¼€
                    if cancelled["value"]:
                        logger.warning(f"âš ï¸ [Session {session_id[:8]}] æ£€æµ‹åˆ°å®¢æˆ·ç«¯æ–­å¼€ï¼Œåœæ­¢å¤„ç†ï¼ˆå·²å¤„ç† {event_count} ä¸ªäº‹ä»¶ï¼‰")
                        break
                    
                    # è½¬æ¢ä¸ºJSONæ ¼å¼
                    response_data = {
                        "type": event.get("type", "unknown"),
                        "content": event.get("content", ""),
                        "timestamp": event.get("timestamp", datetime.now().isoformat()),
                        "session_id": session_id
                    }
                    
                    # æ·»åŠ å¯é€‰å­—æ®µ
                    if "round" in event:
                        response_data["round"] = event["round"]
                    if "tool_name" in event:
                        response_data["tool_name"] = event["tool_name"]
                    if "tool_args" in event:
                        response_data["tool_args"] = event["tool_args"]
                    if "result" in event:
                        response_data["result"] = event["result"]
                    if "code" in event:
                        response_data["code"] = event["code"]
                    if "judgment" in event:
                        response_data["judgment"] = event["judgment"]
                    if "accumulated" in event:
                        response_data["accumulated"] = event["accumulated"]
                    if "is_streaming" in event:
                        response_data["is_streaming"] = event["is_streaming"]
                    if "answer_data" in event:
                        # ä¼˜åŒ–ï¼šä¸º citations æ·»åŠ  preview å­—æ®µï¼ˆå‰50å­—ï¼‰
                        answer_data = event["answer_data"]
                        logger.debug(f"[DEBUG] Processing answer_data: {type(answer_data)}, has citations: {'citations' in answer_data if isinstance(answer_data, dict) else 'N/A'}")
                        if isinstance(answer_data, dict) and "citations" in answer_data:
                            full_citations = answer_data.get("citations", [])
                            logger.debug(f"[DEBUG] Full citations count: {len(full_citations)}")
                            
                            # ä¿å­˜å®Œæ•´çš„ citations åˆ°å…¨å±€å­˜å‚¨ï¼ˆä¾›åç»­æ¥å£æŸ¥è¯¢ï¼‰
                            with session_lock:
                                for citation in full_citations:
                                    citation_id = citation.get("id")
                                    full_content = citation.get("full_content", "")
                                    if citation_id:
                                        # ä½¿ç”¨ citation_id ä½œä¸ºå…¨å±€å”¯ä¸€é”®
                                        global_citations[str(citation_id)] = {
                                            "id": citation_id,
                                            "title": citation.get("title", ""),
                                            "full_content": full_content
                                        }
                                        logger.debug(f"[DEBUG] Saved citation {citation_id} to global_citations")
                            
                            # å¤„ç†å‘é€ç»™å‰ç«¯çš„ citationsï¼ˆåªåŒ…å« previewï¼‰
                            processed_citations = []
                            for citation in full_citations:
                                processed_citation = {
                                    "id": citation.get("id"),
                                    "title": citation.get("title", ""),
                                }
                                # æ·»åŠ  preview å­—æ®µï¼ˆå‰30å­—ï¼‰
                                if "full_content" in citation:
                                    full_content = citation["full_content"]
                                    processed_citation["preview"] = full_content[:30] if len(full_content) > 30 else full_content
                                processed_citations.append(processed_citation)
                            answer_data = answer_data.copy()
                            answer_data["citations"] = processed_citations
                            logger.debug(f"[DEBUG] Processed citations count: {len(processed_citations)}")
                        response_data["answer_data"] = answer_data
                        logger.debug(f"[DEBUG] Added answer_data to response_data, citations: {len(response_data['answer_data'].get('citations', [])) if isinstance(response_data.get('answer_data'), dict) else 'N/A'}")
                    
                    # æ£€æŸ¥æ˜¯å¦æ˜¯ completed äº‹ä»¶
                    if event.get("type") == "completed":
                        has_completed = True
                    
                    # æ•è·æœ€ç»ˆç­”æ¡ˆå†…å®¹ï¼ˆç”¨äºä¿å­˜å†å²ï¼‰
                    event_type = response_data.get('type')
                    if event_type in ['final_answer', 'answer_complete']:
                        if 'answer_data' in response_data and isinstance(response_data['answer_data'], dict):
                            # æå–ç­”æ¡ˆæ­£æ–‡ï¼ˆä¸å«å‚è€ƒæ–‡çŒ®ï¼‰
                            answer_data = response_data['answer_data']
                            final_answer_content = answer_data.get('answer', '')
                        elif 'content' in response_data:
                            # å¦‚æœæ²¡æœ‰answer_dataï¼Œä½¿ç”¨content
                            final_answer_content = response_data.get('content', '')
                    
                    # å‘é€æ•°æ®ï¼ˆæ·»åŠ å¼‚å¸¸å¤„ç†ï¼‰
                    try:
                        # åœ¨åºåˆ—åŒ–å‰è®°å½•äº‹ä»¶ç±»å‹
                        if event_type == 'final_answer':
                            logger.info(f"ğŸ” [Session {session_id[:8]}] å‡†å¤‡åºåˆ—åŒ– final_answer äº‹ä»¶...")
                            logger.info(f"   - answer_dataå­˜åœ¨: {'answer_data' in response_data}")
                            if 'answer_data' in response_data and isinstance(response_data['answer_data'], dict):
                                logger.info(f"   - citationsæ•°é‡: {len(response_data['answer_data'].get('citations', []))}")
                        
                        json_str = json.dumps(response_data, ensure_ascii=False)
                        
                        # è®°å½•å¤§æ•°æ®åŒ…çš„å¤§å°
                        if len(json_str) > 10000:  # è¶…è¿‡ 10KB
                            logger.warning(f"âš ï¸ [Session {session_id[:8]}] å‘é€å¤§æ•°æ®åŒ…: {len(json_str)} å­—èŠ‚, ç±»å‹: {event_type}")
                        elif event_type == 'final_answer':
                            logger.info(f"âœ… [Session {session_id[:8]}] final_answeråºåˆ—åŒ–æˆåŠŸ: {len(json_str)} å­—èŠ‚")
                        
                        yield f"data: {json_str}\n\n"
                        
                        if event_type == 'final_answer':
                            logger.info(f"âœ… [Session {session_id[:8]}] final_answeræ•°æ®å·²yield")
                    except Exception as json_error:
                        # JSONåºåˆ—åŒ–å¤±è´¥ï¼šåªè®°å½•æ—¥å¿—ï¼Œä¸å‘é€erroräº‹ä»¶ç»™å‰ç«¯ï¼ˆé¿å…é‡å¤é”™è¯¯å¡ç‰‡ï¼‰
                        logger.error(f"âŒ [Session {session_id[:8]}] JSONåºåˆ—åŒ–å¤±è´¥: {str(json_error)}")
                        logger.info(f"   Event type: {response_data.get('type')}")
                        import traceback
                        traceback.print_exc()
                        # å°è¯•å‘é€ç®€åŒ–ç‰ˆæœ¬ï¼ˆåªåŒ…å«åŸºæœ¬å­—æ®µï¼‰
                        try:
                            simple_data = {
                                "type": response_data.get("type", "unknown"),
                                "content": str(response_data.get("content", ""))[:500],  # æˆªæ–­å†…å®¹
                                "session_id": session_id,
                                "timestamp": response_data.get("timestamp", datetime.now().isoformat())
                            }
                            yield f"data: {json.dumps(simple_data, ensure_ascii=False)}\n\n"
                        except:
                            logger.error(f"âŒ [Session {session_id[:8]}] è¿ç®€åŒ–æ•°æ®ä¹Ÿæ— æ³•åºåˆ—åŒ–ï¼Œè·³è¿‡æ­¤äº‹ä»¶")
                            pass
                
                # åªæœ‰å½“ agent æ²¡æœ‰å‘é€ completed äº‹ä»¶æ—¶ï¼Œæ‰è¡¥å‘ä¸€ä¸ª
                if not has_completed:
                    logger.warning(f"âš ï¸ [Session {session_id[:8]}] Agentæœªå‘é€completedäº‹ä»¶ï¼Œè¡¥å‘")
                    completed_data = {
                        "type": "completed",
                        "content": "å¤„ç†å®Œæˆ",
                        "session_id": session_id,
                        "timestamp": datetime.now().isoformat()
                    }
                    yield f"data: {json.dumps(completed_data, ensure_ascii=False)}\n\n"
                
                # ä¿å­˜å¯¹è¯å†å²ï¼ˆç”¨æˆ·é—®é¢˜å’Œæœ€ç»ˆç­”æ¡ˆï¼‰
                if final_answer_content.strip():
                    with session_lock:
                        if session_id not in chat_sessions:
                            chat_sessions[session_id] = {
                                "created_at": datetime.now().isoformat(),
                                "messages": []
                            }
                        
                        # æ·»åŠ ç”¨æˆ·é—®é¢˜
                        chat_sessions[session_id]["messages"].append({
                            "role": "user",
                            "content": request.question
                        })
                        
                        # æ·»åŠ åŠ©æ‰‹å›ç­”ï¼ˆåªä¿å­˜ç­”æ¡ˆæ­£æ–‡ï¼Œä¸å«å‚è€ƒæ–‡çŒ®ï¼‰
                        chat_sessions[session_id]["messages"].append({
                            "role": "assistant",
                            "content": final_answer_content.strip()
                        })
                        
                        logger.info(f"ğŸ’¾ [Session {session_id[:8]}] å·²ä¿å­˜å¯¹è¯å†å²ï¼ˆç”¨æˆ·é—®é¢˜ + æœ€ç»ˆç­”æ¡ˆï¼‰")
                
                logger.info(f"âœ… [Session {session_id[:8]}] å¤„ç†å®Œæˆï¼Œé‡Šæ”¾æ§½ä½")
                
            except GeneratorExit:
                # å®¢æˆ·ç«¯ä¸»åŠ¨æ–­å¼€è¿æ¥
                logger.warning(f"âš ï¸ [Session {session_id[:8]}] å®¢æˆ·ç«¯æ–­å¼€è¿æ¥ï¼ˆGeneratorExitï¼‰")
                cancelled["value"] = True
                with session_lock:
                    if session_id in active_sessions:
                        active_sessions[session_id]["status"] = "client_disconnected"
                raise  # é‡æ–°æŠ›å‡ºï¼Œè®© FastAPI å¤„ç†
                    
            except Exception as e:
                logger.error(f"âŒ [Session {session_id[:8]}] Stream generation error: {str(e)}")
                import traceback
                traceback.print_exc()
                try:
                    error_data = {
                        "type": "error",
                        "content": f"æµå¼å¤„ç†å‡ºé”™: {str(e)}",
                                        "session_id": session_id,
                        "timestamp": datetime.now().isoformat()
                    }
                    yield f"data: {json.dumps(error_data, ensure_ascii=False)}\n\n"
        
                    # å‘é€ completed äº‹ä»¶ä»¥ç¡®ä¿æµæ­£ç¡®å…³é—­
                    completed_data = {
                        "type": "completed",
                        "content": "å¤„ç†å¤±è´¥ï¼Œæµç¨‹ç»“æŸ",
                        "session_id": session_id,
                        "timestamp": datetime.now().isoformat()
                    }
                    yield f"data: {json.dumps(completed_data, ensure_ascii=False)}\n\n"
                except:
                    pass  # å¦‚æœæ— æ³•å‘é€é”™è¯¯æ¶ˆæ¯ï¼Œé™é»˜å¤±è´¥
            finally:
                # æ¸…ç†ä¼šè¯è®°å½•
                try:
                    with session_lock:
                        if session_id in active_sessions:
                            # æ ¹æ® cancelled çŠ¶æ€è®¾ç½®ä¸åŒçš„ç»“æŸçŠ¶æ€
                            if cancelled["value"]:
                                active_sessions[session_id]["status"] = "client_disconnected"
                                logger.info(f"âœ… [Session {session_id[:8]}] å®¢æˆ·ç«¯æ–­å¼€ï¼Œä¼šè¯å·²æ¸…ç†")
                            else:
                                active_sessions[session_id]["status"] = "completed"
                                logger.info(f"âœ… [Session {session_id[:8]}] ä¼šè¯æ­£å¸¸å®Œæˆ")
                            active_sessions[session_id]["end_time"] = datetime.now().isoformat()
                except Exception as e:
                    logger.warning(f"âš ï¸ [Session {session_id[:8]}] æ¸…ç†ä¼šè¯è®°å½•å¤±è´¥: {e}")
                
                # æ¸…ç†agentå®ä¾‹
                if agent is not None:
                    try:
                        del agent
                    except:
                        pass
                
                # é‡Šæ”¾ä¿¡å·é‡
                if acquired:
                    try:
                        processing_semaphore.release()
                        logger.info(f"ğŸ”“ [Session {session_id[:8]}] æ§½ä½å·²é‡Šæ”¾")
                    except:
                        pass
        
        # åˆ›å»ºæµå¼å“åº”ï¼Œç¡®ä¿æ•°æ®åŠæ—¶å‘é€
        response = StreamingResponse(
            generate_stream(),
            media_type="text/event-stream",
            headers={
                "Cache-Control": "no-cache",
                "Connection": "keep-alive",
                "X-Accel-Buffering": "no",
                "Access-Control-Allow-Origin": "*",
                "Access-Control-Allow-Headers": "*",
                "Transfer-Encoding": "chunked",
            }
        )
        return response
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"å¤„ç†è¯·æ±‚æ—¶å‡ºé”™: {str(e)}")

@app.post("/chat")
async def chat(request: ChatRequest):
    """éæµå¼èŠå¤©æ¥å£ï¼ˆç”¨äºæµ‹è¯•ï¼‰"""
    if agent_config_template is None:
        raise HTTPException(status_code=500, detail="æ¨ç†ä»£ç†é…ç½®æœªåˆå§‹åŒ–")
    
    session_id = request.session_id or str(uuid.uuid4())
    
    acquired = False
    try:
        # è·å–ä¿¡å·é‡
        acquired = processing_semaphore.acquire(timeout=300)
        if not acquired:
            raise HTTPException(status_code=503, detail="æœåŠ¡å™¨ç¹å¿™ï¼Œè¯·ç¨åé‡è¯•")
        
        # ä¸ºè¿™ä¸ªè¯·æ±‚åˆ›å»ºç‹¬ç«‹çš„agentå®ä¾‹
        agent = create_agent_instance(
            temperature=request.temperature,
            top_p=request.top_p,
            presence_penalty=request.presence_penalty,
            max_tokens=request.max_tokens
        )
        
        # æ”¶é›†æ‰€æœ‰äº‹ä»¶
        events = []
        for event in agent.stream_run(request.question):
            events.append(event)
        
        return {
            "session_id": session_id,
            "question": request.question,
            "events": events,
            "total_events": len(events),
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"å¤„ç†è¯·æ±‚æ—¶å‡ºé”™: {str(e)}")
    finally:
        if acquired:
            processing_semaphore.release()

@app.get("/api/sessions/active")
async def get_active_sessions():
    """è·å–æ­£åœ¨å¤„ç†ä¸­çš„æ´»è·ƒä¼šè¯åˆ—è¡¨ï¼ˆç”¨äºç›‘æ§/è°ƒè¯•ï¼‰"""
    return {
        "active_sessions": active_sessions,
        "total": len(active_sessions),
        "timestamp": datetime.now().isoformat()
    }

@app.get("/citation/{citation_id}")
async def get_citation_detail(citation_id: str):
    """
    è·å–å¼•ç”¨çš„å®Œæ•´å†…å®¹ï¼ˆå…¬å…±æ¥å£ï¼Œä¸ä¾èµ–sessionï¼‰
    
    Args:
        citation_id: å¼•ç”¨ID
        
    Returns:
        å®Œæ•´çš„å¼•ç”¨å†…å®¹
    """
    try:
        with session_lock:
            # å°è¯•å¤šç§ ID æ ¼å¼ï¼ˆå¯èƒ½æ˜¯å­—ç¬¦ä¸²æˆ–æ•°å­—ï¼‰
            citation_data = None
            for possible_id in [citation_id, str(citation_id)]:
                if possible_id in global_citations:
                    citation_data = global_citations[possible_id]
                    break
            
            if citation_data is None:
                return JSONResponse(
                    status_code=404,
                    content={
                        "error": "Citation not found",
                        "message": f"å¼•ç”¨ [{citation_id}] ä¸å­˜åœ¨",
                        "citation_id": citation_id,
                        "available_citations": list(global_citations.keys())[:10]  # åªè¿”å›å‰10ä¸ª
                    }
                )
        
        # è¿”å›å®Œæ•´å†…å®¹
        return {
            "citation_id": citation_data["id"],
            "title": citation_data["title"],
            "full_content": citation_data["full_content"],
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"âŒ è·å–å¼•ç”¨è¯¦æƒ…å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return JSONResponse(
            status_code=500,
            content={
                "error": "Internal server error",
                "message": f"è·å–å¼•ç”¨è¯¦æƒ…å¤±è´¥: {str(e)}"
            }
        )

if __name__ == "__main__":
    logger.info("ğŸ”§ å¯åŠ¨é…ç½®:")
    logger.info(f"   APIç«¯å£: {API_PORT}")
    logger.info(f"   vLLMç«¯å£: {VLLM_PORT}")
    logger.info(f"   æ¨¡å‹è·¯å¾„: {MODEL_PATH}")
    
    uvicorn.run(
        "api_server:app",
        host="0.0.0.0",
        port=API_PORT,
        reload=False,
        log_level="info"
    )





