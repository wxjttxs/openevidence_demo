import json
import re
import logging
from typing import Dict, List, Optional, Tuple
from openai import OpenAI
import os

# é…ç½®æ—¥å¿—
logger = logging.getLogger(__name__)


class AnswerJudgmentSystem:
    """ç­”æ¡ˆåˆ¤æ–­å’Œå¼•ç”¨ç³»ç»Ÿ"""
    
    def __init__(self):
        self.api_key = os.environ.get("API_KEY")
        self.api_base = os.environ.get("API_BASE")
        self.model_name = os.environ.get("LLM_MODEL", "")
        self.summary_model_name = os.environ.get("SUMMARY_MODEL_NAME", "")
        
        self.client = OpenAI(
            api_key=self.api_key,
            base_url=self.api_base,
        )
        
        # åˆ¤æ–­æ£€ç´¢å†…å®¹æ˜¯å¦èƒ½å›ç­”é—®é¢˜çš„æç¤ºè¯ï¼ˆå‹å¥½æ ¼å¼è¾“å‡ºï¼‰
        self.judgment_prompt = """è¯„ä¼°æ£€ç´¢å†…å®¹æ˜¯å¦èƒ½å›ç­”ç”¨æˆ·é—®é¢˜ã€‚

é—®é¢˜: {question}

æ£€ç´¢å†…å®¹:
{retrieval_content}

è¯·æŒ‰ä»¥ä¸‹æ ¼å¼è¾“å‡ºè¯„ä¼°ç»“æœï¼š

**èƒ½å¦å›ç­”**: å¯ä»¥/ä¸èƒ½
**ç½®ä¿¡åº¦**: 0.XX (0.0-1.0ä¹‹é—´çš„æ•°å­—)
**åˆ†æ**: ç®€è¦åˆ†ææ£€ç´¢å†…å®¹æ˜¯å¦èƒ½å¤Ÿå›ç­”é—®é¢˜åŠåŸå› ï¼Œå­—æ•°é™åˆ¶åœ¨300å­—ä»¥å†…ã€‚

æ³¨æ„ï¼šè¾“å‡ºå®Œ"åˆ†æ"å†…å®¹åï¼Œç«‹å³åœæ­¢ã€‚ä¸è¦è¾“å‡ºä»»ä½•JSONæ ¼å¼çš„å†…å®¹ã€‚"""

        # ç”Ÿæˆå¸¦å¼•ç”¨ç­”æ¡ˆçš„æç¤ºè¯
        self.citation_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ä¸´åºŠåŒ»ç”Ÿã€‚è¯·åŸºäºæä¾›çš„æ£€ç´¢å†…å®¹å›ç­”ç”¨æˆ·é—®é¢˜ï¼Œå¹¶ä¸¥æ ¼æŒ‰ç…§å­¦æœ¯è®ºæ–‡æ ¼å¼æ·»åŠ å¼•ç”¨ã€‚

ç”¨æˆ·é—®é¢˜: {question}

æ£€ç´¢å†…å®¹åŠæ¥æº:
{sources_content}

è¦æ±‚ï¼š
When providing final answers, you MUST use academic citation format:
1. Include numbered citations [1][2][3] in your answer text
2. Provide a reference list at the end with format: "Document Title\\n relevant part"
3. Make citations clickable by using the proper format
4. make sure the reference not the same

**CRITICAL: å‚è€ƒæ–‡çŒ®ç¼–å·è§„åˆ™ï¼ˆå¿…é¡»ä¸¥æ ¼éµå®ˆï¼‰**
- ç¼–å·å¿…é¡»ä»1å¼€å§‹ï¼Œä¸¥æ ¼æŒ‰ç…§åœ¨ç­”æ¡ˆä¸­é¦–æ¬¡å‡ºç°çš„é¡ºåºåˆ†é…
- ç¬¬ä¸€ä¸ªå¼•ç”¨çš„å†…å®¹å¿…é¡»æ ‡è®°ä¸º[1]ï¼Œç¬¬äºŒä¸ªä¸º[2]ï¼Œç¬¬ä¸‰ä¸ªä¸º[3]ï¼Œä»¥æ­¤ç±»æ¨
- ç»å¯¹ç¦æ­¢è·³è·ƒç¼–å·ï¼Œå¦‚[1][2][14]æˆ–[1][3][5]ç­‰
- ç¼–å·å¿…é¡»è¿ç»­é€’å¢ï¼š1, 2, 3, 4, 5...
- åœ¨citationsæ•°ç»„ä¸­ï¼Œidå­—æ®µä¹Ÿå¿…é¡»å¯¹åº”ï¼š1, 2, 3, 4, 5...

**é‡è¦ï¼šè¯·åˆ†ä¸¤ä¸ªé˜¶æ®µç”Ÿæˆå†…å®¹**
ç¬¬ä¸€é˜¶æ®µï¼šå…ˆç”Ÿæˆå®Œæ•´çš„ç­”æ¡ˆå†…å®¹ï¼ˆåŒ…å«å¼•ç”¨æ ‡å·ï¼‰
ç¬¬äºŒé˜¶æ®µï¼šç«‹å³ç”Ÿæˆå‚è€ƒæ–‡çŒ®åˆ—è¡¨

Exampleï¼ˆæ­£ç¡®ç¤ºä¾‹ï¼‰:
ç¬¬ä¸€é˜¶æ®µ - ç­”æ¡ˆå†…å®¹:
"ç³–å°¿ç—…ä¸»è¦åˆ†ä¸º1å‹ç³–å°¿ç—…[1]å’Œ2å‹ç³–å°¿ç—…[2]ï¼Œè¿˜æœ‰å¦Šå¨ ç³–å°¿ç—…ç­‰ç‰¹æ®Šç±»å‹[3]ã€‚æ ¹æ®æœ€æ–°æŒ‡å—ï¼Œ1å‹ç³–å°¿ç—…éœ€è¦ç»ˆèº«èƒ°å²›ç´ æ²»ç–—[1]ï¼Œè€Œ2å‹ç³–å°¿ç—…å¯ä»¥é€šè¿‡ç”Ÿæ´»æ–¹å¼å¹²é¢„å’Œè¯ç‰©æ²»ç–—æ¥æ§åˆ¶[2]ã€‚å¦Šå¨ ç³–å°¿ç—…éœ€è¦ç‰¹æ®Šçš„è¡€ç³–ç®¡ç†ç­–ç•¥[3]ã€‚"

ç¬¬äºŒé˜¶æ®µ - å‚è€ƒæ–‡çŒ®:
"å‚è€ƒæ–‡çŒ®:

[1] ç³–å°¿ç—…è¯Šç–—æŒ‡å—.pdf 
è¦ç‚¹ï¼šÂ·é¥®é£Ÿè´¨é‡å’Œèƒ½é‡æ§åˆ¶æ˜¯è¡€ç³–ç®¡ç†çš„åŸºç¡€...

[2] å†…åˆ†æ³Œå­¦æ•™æ.pdf 
è¯¥æ®µè½æ€»ç»“äº†ç”Ÿæ´»æ–¹å¼åŒ»å­¦åœ¨2å‹ç³–å°¿ç—…ï¼ˆT2Dï¼‰åŠç³–å°¿ç—…å‰æœŸé¢„é˜²å’Œç®¡ç†ä¸­çš„å…³é”®ä½œç”¨...

[3] å¦Šå¨ æœŸç–¾ç—…æ‰‹å†Œ.pdf 
è¡Œä¸ºä¸ç”Ÿæ´»æ–¹å¼å¹²é¢„çš„åŸåˆ™..."

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼å›ç­”ï¼ˆæ³¨æ„JSONæ ¼å¼çš„æ­£ç¡®æ€§ï¼‰ï¼š
{{
    "answer": "å®Œæ•´çš„ç­”æ¡ˆå†…å®¹ï¼ŒåŒ…å«å¼•ç”¨æ ‡å·[1][2][3]ç­‰ï¼ˆç¼–å·å¿…é¡»ä»1å¼€å§‹ä¾æ¬¡é€’å¢ï¼‰",
    "citations": [
        {{
            "id": 1,
            "title": "æ–‡æ¡£æ ‡é¢˜",
            "preview": "å¼•ç”¨å†…å®¹å‰30å­—...",
            "full_content": "å®Œæ•´çš„å¼•ç”¨å†…å®¹"
        }},
        {{
            "id": 2,
            "title": "æ–‡æ¡£æ ‡é¢˜",
            "preview": "å¼•ç”¨å†…å®¹å‰30å­—...",
            "full_content": "å®Œæ•´çš„å¼•ç”¨å†…å®¹"
        }}
    ]
}}"""

    def judge_retrieval_sufficiency_stream(self, question: str, retrieval_content: str):
        """æµå¼åˆ¤æ–­æ£€ç´¢å†…å®¹æ˜¯å¦è¶³å¤Ÿå›ç­”é—®é¢˜ - å®æ—¶æµå¼è¾“å‡ºåˆ¤æ–­æ–‡æœ¬"""
        try:
            # ç¡®ä¿è¾“å…¥éƒ½æ˜¯å­—ç¬¦ä¸²
            if not isinstance(question, str):
                question = str(question)
            if not isinstance(retrieval_content, str):
                retrieval_content = str(retrieval_content)
                
            logger.debug(f"[DEBUG] Judging retrieval sufficiency (streaming) for question: {question[:100]}...")
            logger.debug(f"[DEBUG] Retrieval content length: {len(retrieval_content)}")
            
            messages = [
                {
                    "role": "user", 
                    "content": self.judgment_prompt.format(
                        question=question,
                        retrieval_content=retrieval_content
                    )
                }
            ]
            
            # ä½¿ç”¨æµå¼API
            response = self.client.chat.completions.create(
                model=self.model_name,
                messages=messages,
                temperature=0.1,
                max_tokens=500,
                stream=True,
                extra_body={"enable_thinking": False}
            )
            
            # æµå¼æ¥æ”¶å¹¶å®æ—¶å‘é€å†…å®¹
            accumulated_content = ""
            judgment_text = ""
            
            for chunk in response:
                if chunk.choices[0].delta.content:
                    chunk_text = chunk.choices[0].delta.content
                    accumulated_content += chunk_text
                    judgment_text += chunk_text
                    
                    # å®æ—¶å‘é€åˆ¤æ–­æ–‡æœ¬ç‰‡æ®µ
                    yield {
                        "type": "judgment_chunk",
                        "content": chunk_text,
                        "accumulated": judgment_text
                    }
            
            logger.debug(f"[DEBUG] Judgment text complete (length={len(judgment_text)})")
            
            # æµå¼å®Œæˆåï¼Œç›´æ¥ä»æ–‡æœ¬ä¸­æå–åˆ¤æ–­ç»“æœï¼ˆä¸å†ä¾èµ–JSONï¼‰
            try:
                result = self._extract_judgment_from_text(accumulated_content)
                logger.debug(f"[DEBUG] Extracted judgment from text: {result}")
                yield {
                    "type": "judgment_complete",
                    "judgment": result
                }
            except Exception as e:
                logger.debug(f"[DEBUG] Error extracting judgment: {e}")
                # è¿”å›é»˜è®¤å€¼
                yield {
                    "type": "judgment_complete",
                    "judgment": {"can_answer": True, "confidence": 0.5, "reason": "æ— æ³•è§£æåˆ¤æ–­ç»“æœ"}
                }
                
        except Exception as e:
            logger.debug(f"[DEBUG] Error in streaming judgment: {e}")
            import traceback
            traceback.print_exc()
            
            yield {
                "type": "judgment_error",
                "content": f"åˆ¤æ–­è¿‡ç¨‹å‡ºé”™: {str(e)}"
            }

    def judge_retrieval_sufficiency(self, question: str, retrieval_content: str) -> Dict:
        """åˆ¤æ–­æ£€ç´¢å†…å®¹æ˜¯å¦è¶³å¤Ÿå›ç­”é—®é¢˜ - ä½¿ç”¨æµå¼è¾“å‡ºåŠ é€Ÿ"""
        try:
            # ç¡®ä¿è¾“å…¥éƒ½æ˜¯å­—ç¬¦ä¸²
            if not isinstance(question, str):
                question = str(question)
            if not isinstance(retrieval_content, str):
                retrieval_content = str(retrieval_content)
                
            logger.debug(f"[DEBUG] Judging retrieval sufficiency (streaming) for question: {question[:100]}...")
            logger.debug(f"[DEBUG] Retrieval content length: {len(retrieval_content)}")
            
            messages = [
                {
                    "role": "user", 
                    "content": self.judgment_prompt.format(
                        question=question,
                        retrieval_content=retrieval_content
                    )
                }
            ]
            
            # ä½¿ç”¨æµå¼APIåŠ é€Ÿå“åº”ï¼Œé™åˆ¶tokenæ•°ä»¥åŠ å¿«åˆ¤æ–­é€Ÿåº¦
            response = self.client.chat.completions.create(
                model=self.model_name,
                messages=messages,
                temperature=0.1,  # é™ä½æ¸©åº¦ï¼Œæé«˜ç¡®å®šæ€§å’Œé€Ÿåº¦
                max_tokens=500,  # å¤§å¹…å‡å°‘tokenæ•°ï¼ŒåŠ å¿«å“åº”ï¼ˆåˆ¤æ–­åªéœ€è¦ç®€çŸ­çš„JSONï¼‰
                stream=True,  # æ”¹ä¸ºæµå¼
                extra_body={"enable_thinking": False}
            )
            
            # æµå¼æ¥æ”¶å¹¶ç´¯ç§¯å†…å®¹ï¼Œå°è¯•æå‰æ£€æµ‹å®Œæ•´JSON
            content = ""
            early_parsed = False
            for chunk in response:
                if chunk.choices[0].delta.content:
                    content += chunk.choices[0].delta.content
                    
                    # å°è¯•æå‰æ£€æµ‹å®Œæ•´çš„JSONå¯¹è±¡ï¼ˆå½“æ£€æµ‹åˆ° }} æ—¶ï¼‰
                    if not early_parsed and content.count('}') >= 2:
                        try:
                            # å°è¯•è§£æå½“å‰ç´¯ç§¯çš„å†…å®¹
                            temp_content = content.strip()
                            if temp_content.startswith("```json"):
                                temp_content = temp_content.replace("```json", "").strip()
                            elif temp_content.startswith("```"):
                                temp_content = temp_content.replace("```", "").strip()
                            
                            # å°è¯•æ‰¾åˆ°ç¬¬ä¸€ä¸ªå®Œæ•´çš„JSONå¯¹è±¡
                            if '{' in temp_content and '}' in temp_content:
                                start = temp_content.find('{')
                                # ç®€å•çš„æ‹¬å·åŒ¹é…
                                depth = 0
                                end = -1
                                for i in range(start, len(temp_content)):
                                    if temp_content[i] == '{':
                                        depth += 1
                                    elif temp_content[i] == '}':
                                        depth -= 1
                                        if depth == 0:
                                            end = i + 1
                                            break
                                
                                if end > 0:
                                    json_str = temp_content[start:end]
                                    result = json.loads(json_str)
                                    # æ£€æŸ¥æ˜¯å¦åŒ…å«å¿…è¦å­—æ®µ
                                    if 'can_answer' in result and 'confidence' in result:
                                        logger.debug(f"[DEBUG] Early parsed judgment result from stream")
                                        early_parsed = True
                                        # ç»§ç»­æ¥æ”¶å‰©ä½™å†…å®¹ï¼Œä½†ä¸å†å°è¯•è§£æ
                                        break
                        except:
                            pass  # ç»§ç»­æ¥æ”¶æ›´å¤šå†…å®¹
            
            logger.debug(f"[DEBUG] Judgment response (streamed, length={len(content)}): {content[:200]}...")
            
            # å°è¯•è§£æJSONï¼ˆæ”¯æŒmarkdownåŒ…è£¹çš„JSONï¼‰
            try:
                # é¦–å…ˆå°è¯•ç›´æ¥è§£æ
                result = json.loads(content)
                logger.debug(f"[DEBUG] Parsed judgment result: {result}")
                return result
            except json.JSONDecodeError:
                # å°è¯•æ¸…ç†markdownæ ‡è®°åå†è§£æ
                cleaned_content = content.strip()
                if cleaned_content.startswith("```json"):
                    cleaned_content = cleaned_content.replace("```json", "").replace("```", "").strip()
                elif cleaned_content.startswith("```"):
                    cleaned_content = cleaned_content.replace("```", "").strip()
                
                try:
                    result = json.loads(cleaned_content)
                    logger.debug(f"[DEBUG] Parsed judgment result after cleaning: {result}")
                    return result
                except json.JSONDecodeError:
                    # å¦‚æœä»ç„¶æ— æ³•è§£æï¼Œå°è¯•ä»æ–‡æœ¬ä¸­æå–
                    logger.debug(f"[DEBUG] Failed to parse JSON even after cleaning, extracting from text")
                    return self._extract_judgment_from_text(content)
                
        except Exception as e:
            logger.debug(f"[DEBUG] Error in judgment: {e}")
            import traceback
            traceback.print_exc()
            return {
                "can_answer": False,
                "confidence": 0.0,
                "reason": f"åˆ¤æ–­è¿‡ç¨‹å‡ºé”™: {str(e)}",
                "missing_info": "æ— æ³•è¯„ä¼°"
            }

    def _pre_generate_citations(self, question: str, retrieval_results: List[Dict]) -> List[Dict]:
        """
        é¢„ç”Ÿæˆå‚è€ƒæ–‡çŒ®åˆ—è¡¨ï¼ˆä½¿ç”¨retrieval_XXç¼–å·ï¼‰
        
        Args:
            question: ç”¨æˆ·é—®é¢˜
            retrieval_results: æ£€ç´¢ç»“æœåˆ—è¡¨
            
        Returns:
            List[Dict]: é¢„ç”Ÿæˆçš„å‚è€ƒæ–‡çŒ®åˆ—è¡¨ï¼ŒåŒ…å«retrieval_idå­—æ®µ
        """
        try:
            # åŸºäºæ£€ç´¢ç»“æœç›´æ¥æ„é€ å‚è€ƒæ–‡çŒ®ï¼Œä½¿ç”¨retrieval_01åˆ°retrieval_XXçš„ç¼–å·ï¼ˆæŒ‰å®é™…æ•°é‡ï¼‰
            citations = []
            
            for i in range(len(retrieval_results)):
                result = retrieval_results[i]
                # æ ¹æ®å®é™…æ•°é‡å†³å®šç¼–å·æ ¼å¼ï¼š1-9ç”¨01-09ï¼Œ10ä»¥ä¸Šç”¨å®é™…æ•°å­—
                if i + 1 < 10:
                    retrieval_id = f"retrieval_{i+1:02d}"  # retrieval_01, retrieval_02, ..., retrieval_09
                else:
                    retrieval_id = f"retrieval_{i+1}"  # retrieval_10, retrieval_11, ...
                
                citation = {
                    "id": i + 1,  # ä¸´æ—¶IDï¼Œåç»­ä¼šè¢«æ›¿æ¢
                    "retrieval_id": retrieval_id,  # æ£€ç´¢ç¼–å·ï¼šretrieval_01, retrieval_02, ...
                    "title": result.get("title", f"æ–‡æ¡£ {i+1}"),
                    "preview": result.get("content", "")[:30] + "..." if len(result.get("content", "")) > 30 else result.get("content", ""),
                    "full_content": result.get("content", "")
                }
                citations.append(citation)
            
            logger.debug(f"[DEBUG] é¢„ç”Ÿæˆå‚è€ƒæ–‡çŒ®å®Œæˆ: {len(citations)} items")
            return citations
            
        except Exception as e:
            logger.debug(f"[DEBUG] é¢„ç”Ÿæˆå‚è€ƒæ–‡çŒ®å¤±è´¥: {e}")
            return []

    def generate_answer_with_citations_stream(self, question: str, retrieval_results: List[Dict]):
        """
        æµå¼ç”Ÿæˆå¸¦å¼•ç”¨çš„ç­”æ¡ˆ - é¢„ç”Ÿæˆå‚è€ƒæ–‡çŒ®ä¼˜åŒ–ç‰ˆæœ¬
        
        ä¼˜åŒ–ç­–ç•¥ï¼š
        1. å…ˆåŸºäºæ£€ç´¢ç»“æœé¢„ç”Ÿæˆå‚è€ƒæ–‡çŒ®
        2. ç„¶åæµå¼ç”Ÿæˆç­”æ¡ˆæ–‡æœ¬
        3. ç­”æ¡ˆç”Ÿæˆå®Œæˆåç«‹å³æ˜¾ç¤ºé¢„ç”Ÿæˆçš„å‚è€ƒæ–‡çŒ®
        """
        try:
            # å‡†å¤‡æ¥æºå†…å®¹
            sources_content = self.create_sources_content_for_citation(retrieval_results)
            
            logger.debug(f"[DEBUG] Streaming answer generation for question: {question[:100]}...")
            logger.debug(f"[DEBUG] Sources content length: {len(sources_content)}")
            
            # ç¬¬ä¸€æ­¥ï¼šé¢„ç”Ÿæˆå‚è€ƒæ–‡çŒ®
            logger.debug(f"[DEBUG] é¢„ç”Ÿæˆå‚è€ƒæ–‡çŒ®...")
            pre_generated_citations = self._pre_generate_citations(question, retrieval_results)
            
            # ç¬¬äºŒæ­¥ï¼šæµå¼ç”Ÿæˆç­”æ¡ˆæ–‡æœ¬ï¼ˆä¸åŒ…å«å‚è€ƒæ–‡çŒ®ï¼‰
            answer_prompt = f"""**è¯·æ ¹æ®ä»¥ä¸‹æ£€ç´¢å†…å®¹å›ç­”ç”¨æˆ·é—®é¢˜ï¼š**

**æç¤ºï¼š** åœ¨å›ç­”ä¸­å¼•ç”¨æ–‡çŒ®æ—¶ï¼Œ**å¿…é¡»ä½¿ç”¨ref01, ref02, ref03...è¿™æ ·çš„ç¼–å·æ ¼å¼**ï¼Œä»ref01å¼€å§‹ï¼ŒæŒ‰é¦–æ¬¡å¼•ç”¨çš„é¡ºåºä¾æ¬¡é€’å¢ã€‚**ä¸è¦ç”Ÿæˆå‚è€ƒæ–‡çŒ®åˆ—è¡¨**ã€‚**ä¸è¦åœ¨ç­”æ¡ˆä¸­æ·»åŠ ä»»ä½•æ³¨é‡Šè¯´æ˜**ã€‚

## å¼•ç”¨ç¼–å·è§„åˆ™ï¼ˆä¸¥æ ¼éµå®ˆï¼‰ï¼š

* **é‡è¦**ï¼šæ£€ç´¢å†…å®¹ä¸­çš„æ¯ç¯‡æ–‡çŒ®å·²ç»æ ‡è®°äº†ç¼–å· [retrieval_01], [retrieval_02], [retrieval_03]...ï¼ˆè§ä¸‹æ–¹æ£€ç´¢å†…å®¹ï¼‰
* **ä½†åœ¨ç­”æ¡ˆä¸­å¼•ç”¨æ—¶ï¼Œå¿…é¡»ä½¿ç”¨ref01, ref02, ref03...è¿™æ ·çš„æ ¼å¼**
* **ç¼–å·å¿…é¡»ä»ref01å¼€å§‹ï¼ŒæŒ‰é¦–æ¬¡å¼•ç”¨çš„é¡ºåºè¿ç»­é€’å¢**
* **å¼•ç”¨æ ¼å¼**ï¼šåœ¨ç­”æ¡ˆä¸­ä½¿ç”¨ [ref01], [ref02], [ref03]... è¿™æ ·çš„æ ¼å¼å¼•ç”¨æ–‡çŒ®
* **æ˜ å°„è¯´æ˜**ï¼šåœ¨é¦–æ¬¡å¼•ç”¨æŸä¸ªæ–‡çŒ®æ—¶ï¼Œå¯ä»¥åœ¨refç¼–å·åæ³¨æ˜å¯¹åº”çš„retrievalç¼–å·ï¼Œæ ¼å¼ä¸º [ref01(retrieval_03)]ï¼Œåç»­å¼•ç”¨åŒä¸€æ–‡çŒ®æ—¶åªéœ€ä½¿ç”¨ [ref01]
* **ç¦æ­¢æ·»åŠ æ³¨é‡Š**ï¼šä¸è¦åœ¨ç­”æ¡ˆä¸­æ·»åŠ ä»»ä½•å…³äºå¼•ç”¨æ˜ å°„çš„æ³¨é‡Šè¯´æ˜ï¼ˆå¦‚"æ³¨ï¼š[retrieval_01]ä¸[retrieval_02]å†…å®¹ä¸€è‡´"ç­‰ï¼‰ï¼Œåªè¾“å‡ºç­”æ¡ˆå†…å®¹æœ¬èº«

**æ­£ç¡®ç¤ºä¾‹ï¼š**
æ£€ç´¢ç»“æœï¼š
[retrieval_01] æ ‡é¢˜: ç³–å°¿ç—…è¯Šæ–­æŒ‡å—
[retrieval_02] æ ‡é¢˜: ç³–å°¿ç—…æ²»ç–—æŒ‡å—  
[retrieval_03] æ ‡é¢˜: ç³–å°¿ç—…å¹¶å‘ç—‡æŒ‡å—

å¦‚æœç­”æ¡ˆä¸­å…ˆå¼•ç”¨retrieval_03ï¼Œå†å¼•ç”¨retrieval_01ï¼Œåº”è¯¥å†™ï¼š
"ç³–å°¿ç—…å¹¶å‘ç—‡éœ€è¦ç‰¹åˆ«æ³¨æ„[ref01(retrieval_03)]ï¼ŒåŒæ—¶éµå¾ªè¯Šæ–­æ ‡å‡†[ref02(retrieval_01)]..."
æˆ–è€…ï¼š
"ç³–å°¿ç—…å¹¶å‘ç—‡éœ€è¦ç‰¹åˆ«æ³¨æ„[ref01]ï¼ŒåŒæ—¶éµå¾ªè¯Šæ–­æ ‡å‡†[ref02]..."

**é”™è¯¯ç¤ºä¾‹ï¼š**
"ç³–å°¿ç—…å¹¶å‘ç—‡éœ€è¦ç‰¹åˆ«æ³¨æ„[retrieval_03]ï¼ŒåŒæ—¶éµå¾ªè¯Šæ–­æ ‡å‡†[retrieval_01]..." â† é”™è¯¯ï¼å¿…é¡»ä½¿ç”¨ref01, ref02æ ¼å¼
"ç³–å°¿ç—…å¹¶å‘ç—‡éœ€è¦ç‰¹åˆ«æ³¨æ„[ref02]ï¼ŒåŒæ—¶éµå¾ªè¯Šæ–­æ ‡å‡†[ref01]..." â† é”™è¯¯ï¼å¿…é¡»ä»ref01å¼€å§‹ï¼ŒæŒ‰é¡ºåºé€’å¢

---
## æ£€ç´¢å†…å®¹ï¼š{sources_content}

## é—®é¢˜å¦‚ä¸‹ï¼š"""
            
            messages = [
                {
                    "role": "system",
                    "content": answer_prompt
                },
                {
                    "role": "user",
                    "content": question
                }
            ]
            
            # ä½¿ç”¨æµå¼APIï¼ˆä¼˜åŒ–é¦–tokenå“åº”é€Ÿåº¦ï¼‰
            import time
            api_start_time = time.time()
            logger.info(f"ğŸš€ å¼€å§‹è°ƒç”¨ç­”æ¡ˆç”ŸæˆAPI (æ¨¡å‹: {self.summary_model_name})")
            
            response = self.client.chat.completions.create(
                model=self.summary_model_name,
                messages=messages,
                temperature=0.1,  # æä½temperatureç¡®ä¿ä¸¥æ ¼éµå®ˆè§„åˆ™
                max_tokens=2048,  # è¿›ä¸€æ­¥å‡å°‘max_tokensåŠ å¿«é¦–token (4096â†’2048)
                stream=True  # å¯ç”¨æµå¼
            )
            
            accumulated_content = ""
            answer_text = ""
            last_yield_length = 0  # è®°å½•ä¸Šæ¬¡å‘é€çš„ä½ç½®
            citations_sent = False  # æ ‡è®°æ˜¯å¦å·²å‘é€citations
            first_token_received = False  # æ ‡è®°é¦–token
            
            # ç®€åŒ–çš„æµå¼ç”Ÿæˆé€»è¾‘
            for chunk in response:
                if chunk.choices[0].delta.content:
                    content_piece = chunk.choices[0].delta.content
                    
                    # è®°å½•é¦–tokenæ—¶é—´
                    if not first_token_received:
                        first_token_time = time.time() - api_start_time
                        logger.info(f"âš¡ æ”¶åˆ°é¦–ä¸ªtokenï¼Œè€—æ—¶: {first_token_time:.2f}ç§’")
                        first_token_received = True
                    
                    accumulated_content += content_piece
                    answer_text += content_piece
                    
                    # å‘é€ç­”æ¡ˆç‰‡æ®µ
                    if len(answer_text) > last_yield_length:
                        new_content = answer_text[last_yield_length:]
                        last_yield_length = len(answer_text)
                        
                        if new_content:
                            yield {
                                "type": "answer_chunk",
                                "content": new_content,
                            }
            
            # æµå¼å®Œæˆåï¼Œè¿‡æ»¤å¹¶å‘é€å®é™…ä½¿ç”¨çš„å‚è€ƒæ–‡çŒ®
            logger.debug(f"[DEBUG] Stream completed, answer length: {len(answer_text)}")
            
            if not citations_sent and pre_generated_citations:
                # æå–ç­”æ¡ˆä¸­å®é™…ä½¿ç”¨çš„å¼•ç”¨ç¼–å·ï¼ˆref01, ref02, ref03...æ ¼å¼ï¼‰
                import re
                ref_citations = []  # å­˜å‚¨æŒ‰é¦–æ¬¡å‡ºç°é¡ºåºçš„refç¼–å·
                ref_to_retrieval = {}  # {ref01: retrieval_01, ref02: retrieval_02, ...}
                
                # åŒ¹é… [ref01], [ref02]... æˆ– [ref01(retrieval_XX)] æ ¼å¼ï¼ˆä¸åŒºåˆ†å¤§å°å†™ï¼‰
                # å…ˆåŒ¹é…å¸¦æ‹¬å·çš„æ ¼å¼: [ref01(retrieval_03)]
                for match in re.finditer(r'\[ref(\d+)\(retrieval_\d+\)\]', answer_text, re.IGNORECASE):
                    ref_num = int(match.group(1))
                    ref_id = f"ref{ref_num:02d}"  # ref01, ref02, ...
                    if ref_id not in ref_citations:
                        ref_citations.append(ref_id)
                
                # å†åŒ¹é…ä¸å¸¦æ‹¬å·çš„æ ¼å¼: [ref01]ï¼ˆé¿å…é‡å¤æ·»åŠ ï¼‰
                for match in re.finditer(r'\[ref(\d+)\]', answer_text, re.IGNORECASE):
                    ref_num = int(match.group(1))
                    ref_id = f"ref{ref_num:02d}"  # ref01, ref02, ...
                    if ref_id not in ref_citations:
                        ref_citations.append(ref_id)
                
                logger.info(f"ğŸ“š ç­”æ¡ˆä¸­å¼•ç”¨çš„refç¼–å·ï¼ˆæŒ‰é¦–æ¬¡å‡ºç°é¡ºåºï¼‰: {ref_citations}")
                
                # åˆ›å»ºretrieval_idåˆ°citationçš„æ˜ å°„
                retrieval_to_citation = {}
                for c in pre_generated_citations:
                    retrieval_id = c.get('retrieval_id', f'retrieval_{c["id"]:02d}')
                    retrieval_to_citation[retrieval_id] = c
                
                # å»ºç«‹refåˆ°retrievalçš„æ˜ å°„å…³ç³»
                # æ–¹æ³•ï¼šä»ç­”æ¡ˆä¸­æå–refç¼–å·å¯¹åº”çš„retrieval_id
                # æŸ¥æ‰¾ç­”æ¡ˆä¸­refç¼–å·é™„è¿‘æ˜¯å¦æœ‰retrieval_XXçš„å¼•ç”¨
                used_citations = []
                
                for ref_idx, ref_id in enumerate(ref_citations):
                    # å°è¯•ä»ç­”æ¡ˆä¸­æ‰¾åˆ°ref_idå¯¹åº”çš„retrieval_id
                    # æ–¹æ³•1ï¼šæŸ¥æ‰¾ref_idåæ˜¯å¦æœ‰(retrieval_XX)çš„è¯´æ˜ï¼Œæ ¼å¼ä¸º [ref01(retrieval_03)]
                    ref_with_retrieval_pattern = rf'\[{re.escape(ref_id)}\(retrieval_(\d+)\)\]'
                    match = re.search(ref_with_retrieval_pattern, answer_text, re.IGNORECASE)
                    
                    retrieval_id = None
                    if match:
                        # æ‰¾åˆ°äº†æ˜ç¡®çš„æ˜ å°„å…³ç³»
                        retrieval_num = int(match.group(1))
                        # æ ¹æ®æ•°å­—å¤§å°å†³å®šæ ¼å¼ï¼š1-9ç”¨01-09ï¼Œ10ä»¥ä¸Šç”¨å®é™…æ•°å­—
                        if retrieval_num < 10:
                            retrieval_id = f"retrieval_{retrieval_num:02d}"  # retrieval_01, retrieval_02, ...
                        else:
                            retrieval_id = f"retrieval_{retrieval_num}"  # retrieval_10, retrieval_11, ...
                        logger.debug(f"âœ… æ‰¾åˆ°æ˜ å°„å…³ç³»: {ref_id} -> {retrieval_id}")
                    else:
                        # æ–¹æ³•2ï¼šæŸ¥æ‰¾ref_idé™„è¿‘æ˜¯å¦æœ‰retrieval_XXå¼•ç”¨
                        # æŸ¥æ‰¾ref_idå‰å50ä¸ªå­—ç¬¦èŒƒå›´å†…çš„retrieval_XX
                        ref_positions = [m.start() for m in re.finditer(rf'\[{re.escape(ref_id)}\]', answer_text, re.IGNORECASE)]
                        if ref_positions:
                            ref_pos = ref_positions[0]  # ä½¿ç”¨ç¬¬ä¸€ä¸ªå‡ºç°çš„ä½ç½®
                            context_start = max(0, ref_pos - 50)
                            context_end = min(len(answer_text), ref_pos + 50)
                            context = answer_text[context_start:context_end]
                            
                            # åœ¨ä¸Šä¸‹æ–‡ä¸­æŸ¥æ‰¾retrieval_XXï¼ˆåŒ¹é…retrieval_01æˆ–retrieval_10ç­‰æ ¼å¼ï¼‰
                            retrieval_match = re.search(r'retrieval_(\d+)', context, re.IGNORECASE)
                            if retrieval_match:
                                retrieval_num = int(retrieval_match.group(1))
                                # æ ¹æ®æ•°å­—å¤§å°å†³å®šæ ¼å¼ï¼š1-9ç”¨01-09ï¼Œ10ä»¥ä¸Šç”¨å®é™…æ•°å­—
                                if retrieval_num < 10:
                                    retrieval_id = f"retrieval_{retrieval_num:02d}"  # retrieval_01, retrieval_02, ...
                                else:
                                    retrieval_id = f"retrieval_{retrieval_num}"  # retrieval_10, retrieval_11, ...
                                logger.debug(f"âœ… åœ¨ä¸Šä¸‹æ–‡ä¸­æ‰¾åˆ°æ˜ å°„å…³ç³»: {ref_id} -> {retrieval_id}")
                    
                    # å¦‚æœæ²¡æ‰¾åˆ°æ˜ç¡®çš„æ˜ å°„ï¼ŒæŒ‰refç¼–å·é¡ºåºä¾æ¬¡æ˜ å°„åˆ°æ£€ç´¢ç»“æœ
                    # è¿™é‡Œç®€åŒ–å¤„ç†ï¼šæŒ‰refç¼–å·é¡ºåºï¼Œä¾æ¬¡é€‰æ‹©æ£€ç´¢ç»“æœ
                    if not retrieval_id:
                        # æŒ‰é¡ºåºé€‰æ‹©ï¼šref01 -> retrieval_01, ref02 -> retrieval_02...
                        # æ³¨æ„ï¼šè¿™ä¸æ˜¯æœ€ä¼˜æ–¹æ¡ˆï¼Œä½†å¯ä»¥ä¿è¯æœ‰æ˜ å°„å…³ç³»
                        if ref_idx < len(pre_generated_citations):
                            # ä»é¢„ç”Ÿæˆçš„citationsä¸­è·å–retrieval_idï¼ˆå·²ç»æ­£ç¡®æ ¼å¼åŒ–ï¼‰
                            retrieval_id = pre_generated_citations[ref_idx].get('retrieval_id')
                            if not retrieval_id:
                                # å¦‚æœæ²¡æœ‰retrieval_idï¼Œæ ¹æ®ç´¢å¼•ç”Ÿæˆ
                                if ref_idx + 1 < 10:
                                    retrieval_id = f'retrieval_{ref_idx+1:02d}'
                                else:
                                    retrieval_id = f'retrieval_{ref_idx+1}'
                            logger.debug(f"âš ï¸ æœªæ‰¾åˆ°æ˜ç¡®æ˜ å°„ï¼Œä½¿ç”¨é¡ºåºæ˜ å°„: {ref_id} -> {retrieval_id}")
                        else:
                            logger.warning(f"âš ï¸ refç¼–å· {ref_id} è¶…å‡ºæ£€ç´¢ç»“æœèŒƒå›´")
                            continue
                    
                    if retrieval_id in retrieval_to_citation:
                        citation = retrieval_to_citation[retrieval_id].copy()
                        citation['id'] = ref_idx + 1  # é‡æ–°ç¼–å·ä¸º1, 2, 3...ï¼ˆç”¨äºæœ€ç»ˆæ˜¾ç¤ºï¼‰
                        citation['ref_id'] = ref_id  # ä¿å­˜refç¼–å·ï¼ˆref01, ref02...ï¼‰
                        citation['retrieval_id'] = retrieval_id  # ä¿å­˜retrievalç¼–å·ï¼ˆretrieval_01, retrieval_02...ï¼‰
                        used_citations.append(citation)
                        ref_to_retrieval[ref_id] = retrieval_id
                    else:
                        logger.warning(f"âš ï¸ refç¼–å· {ref_id} å¯¹åº”çš„ retrieval_id {retrieval_id} ä¸å­˜åœ¨")
                
                # æ›¿æ¢ç­”æ¡ˆä¸­çš„refç¼–å·ä¸ºè¿ç»­çš„æ•°å­—ç¼–å· [1], [2], [3]...
                final_answer_text = answer_text
                replacement_count = 0
                
                for ref_idx, ref_id in enumerate(ref_citations):
                    ref_num = ref_idx + 1
                    # æ›¿æ¢æ‰€æœ‰ [refXX] ä¸º [æ•°å­—]ï¼ˆä¸åŒºåˆ†å¤§å°å†™ï¼‰
                    # å…ˆå¤„ç†å¸¦æ‹¬å·çš„æ ¼å¼: [ref01(retrieval_XX)] -> [1]ï¼ˆä¼˜å…ˆçº§æ›´é«˜ï¼Œé¿å…é‡å¤æ›¿æ¢ï¼‰
                    pattern_with_bracket = rf'\[{re.escape(ref_id)}\(retrieval_\d+\)\]'
                    matches_before = len(re.findall(pattern_with_bracket, final_answer_text, re.IGNORECASE))
                    final_answer_text = re.sub(pattern_with_bracket, f'[{ref_num}]', final_answer_text, flags=re.IGNORECASE)
                    matches_after = len(re.findall(pattern_with_bracket, final_answer_text, re.IGNORECASE))
                    if matches_before > 0:
                        replacement_count += matches_before
                        logger.debug(f"âœ… æ›¿æ¢ {matches_before} å¤„ [{ref_id}(retrieval_XX)] -> [{ref_num}]")
                    
                    # å†å¤„ç†ä¸å¸¦æ‹¬å·çš„æ ¼å¼: [ref01] -> [1]
                    pattern_simple = rf'\[{re.escape(ref_id)}\]'
                    matches_before2 = len(re.findall(pattern_simple, final_answer_text, re.IGNORECASE))
                    final_answer_text = re.sub(pattern_simple, f'[{ref_num}]', final_answer_text, flags=re.IGNORECASE)
                    matches_after2 = len(re.findall(pattern_simple, final_answer_text, re.IGNORECASE))
                    if matches_before2 > 0:
                        replacement_count += matches_before2
                        logger.debug(f"âœ… æ›¿æ¢ {matches_before2} å¤„ [{ref_id}] -> [{ref_num}]")
                
                logger.info(f"ğŸ“ ç­”æ¡ˆæ–‡æœ¬æ›¿æ¢å®Œæˆï¼Œå…±æ›¿æ¢ {replacement_count} å¤„")
                
                # æ¸…ç†ç­”æ¡ˆä¸­çš„æ³¨é‡Šè¯´æ˜ï¼ˆå¦‚"æ³¨ï¼š[retrieval_01]ä¸[retrieval_02]å†…å®¹ä¸€è‡´ï¼Œé¦–æ¬¡å¼•ç”¨æ ‡è®°ä¸ºref01ã€‚"ï¼‰
                # åŒ¹é…å„ç§å¯èƒ½çš„æ³¨é‡Šæ ¼å¼ï¼ˆæ›´å®½æ³›çš„åŒ¹é…ï¼Œç¡®ä¿èƒ½åŒ¹é…æ‰€æœ‰å˜ä½“ï¼‰
                comment_patterns = [
                    r'æ³¨[ï¼š:].*?retrieval_\d+.*?å†…å®¹ä¸€è‡´.*?é¦–æ¬¡å¼•ç”¨æ ‡è®°ä¸ºref\d+[ã€‚.]?\s*',  # æ³¨ï¼š[retrieval_01]ä¸[retrieval_02]å†…å®¹ä¸€è‡´ï¼Œé¦–æ¬¡å¼•ç”¨æ ‡è®°ä¸ºref01ã€‚
                    r'æ³¨[ï¼š:].*?retrieval_\d+.*?å†…å®¹ä¸€è‡´.*?[ã€‚.]?\s*',  # æ³¨ï¼š[retrieval_01]ä¸[retrieval_02]å†…å®¹ä¸€è‡´
                    r'\[retrieval_\d+\].*?å†…å®¹ä¸€è‡´.*?é¦–æ¬¡å¼•ç”¨æ ‡è®°ä¸ºref\d+[ã€‚.]?\s*',  # [retrieval_01]ä¸[retrieval_02]å†…å®¹ä¸€è‡´ï¼Œé¦–æ¬¡å¼•ç”¨æ ‡è®°ä¸ºref01ã€‚
                    r'æ³¨[ï¼š:].*?ref\d+.*?',  # æ³¨ï¼š...ref01...ï¼ˆåŒ¹é…ä»»ä½•åŒ…å«refç¼–å·çš„æ³¨é‡Šï¼‰
                ]
                
                cleaned_text = final_answer_text
                removed_comments = 0
                for pattern in comment_patterns:
                    matches = re.findall(pattern, cleaned_text, re.IGNORECASE | re.DOTALL)
                    if matches:
                        removed_comments += len(matches)
                        cleaned_text = re.sub(pattern, '', cleaned_text, flags=re.IGNORECASE | re.DOTALL)
                        logger.debug(f"ç§»é™¤æ³¨é‡Š: {matches[0][:50]}...")
                
                # æ¸…ç†å¤šä½™çš„ç©ºè¡Œï¼ˆè¿ç»­ä¸¤ä¸ªæˆ–æ›´å¤šæ¢è¡Œç¬¦æ›¿æ¢ä¸ºä¸€ä¸ªï¼‰
                cleaned_text = re.sub(r'\n{3,}', '\n\n', cleaned_text)
                # æ¸…ç†è¡Œé¦–è¡Œå°¾çš„ç©ºç™½
                cleaned_text = cleaned_text.strip()
                
                if removed_comments > 0:
                    logger.info(f"ğŸ§¹ æ¸…ç†äº† {removed_comments} æ¡æ³¨é‡Šè¯´æ˜")
                    final_answer_text = cleaned_text
                
                if final_answer_text != answer_text:
                    logger.info(f"âœ… æ›¿æ¢æˆåŠŸï¼šåŸå§‹æ–‡æœ¬é•¿åº¦ {len(answer_text)}, æ›¿æ¢åé•¿åº¦ {len(final_answer_text)}")
                    # æ˜¾ç¤ºæ›¿æ¢å‰åçš„å¯¹æ¯”
                    import difflib
                    diff = list(difflib.unified_diff(
                        answer_text.splitlines(keepends=True),
                        final_answer_text.splitlines(keepends=True),
                        lineterm='',
                        n=0
                    ))
                    if diff:
                        logger.debug(f"æ›¿æ¢å·®å¼‚é¢„è§ˆ: {''.join(diff[:10])}")
                else:
                    logger.warning(f"âš ï¸ æ›¿æ¢æœªç”Ÿæ•ˆï¼ŒåŸå§‹æ–‡æœ¬å’Œæ›¿æ¢åæ–‡æœ¬ç›¸åŒ")
                    logger.debug(f"åŸå§‹æ–‡æœ¬åŒ…å«ref01: {'ref01' in answer_text}")
                    logger.debug(f"åŸå§‹æ–‡æœ¬åŒ…å«ref02: {'ref02' in answer_text}")
                
                # æ£€æŸ¥æ˜¯å¦æœ‰æ›¿æ¢å‘ç”Ÿ
                if final_answer_text != answer_text:
                    logger.info(f"âœ… æˆåŠŸæ›¿æ¢äº†ç­”æ¡ˆä¸­çš„refç¼–å·")
                    # å‘é€æ›¿æ¢åçš„å®Œæ•´ç­”æ¡ˆï¼ˆç”¨äºæ›¿æ¢æµå¼è¾“å‡ºçš„åŸå§‹å†…å®¹ï¼‰
                    yield {
                        "type": "answer_chunk",
                        "content": final_answer_text,  # å‘é€å®Œæ•´çš„æ›¿æ¢åç­”æ¡ˆ
                        "is_final": True  # æ ‡è®°è¿™æ˜¯æœ€ç»ˆç‰ˆæœ¬ï¼Œåº”è¯¥æ›¿æ¢ä¹‹å‰çš„å†…å®¹
                    }
                else:
                    logger.warning(f"âš ï¸ ç­”æ¡ˆæ–‡æœ¬æ›¿æ¢æœªç”Ÿæ•ˆï¼ŒåŸå§‹æ–‡æœ¬å’Œæ›¿æ¢åæ–‡æœ¬ç›¸åŒ")
                
                logger.info(f"ğŸ“š æœ€ç»ˆä½¿ç”¨çš„å‚è€ƒæ–‡çŒ®æ•°é‡: {len(used_citations)}/{len(pre_generated_citations)}")
                logger.info(f"ğŸ“š refåˆ°retrievalçš„æ˜ å°„å…³ç³»: {ref_to_retrieval}")
                logger.info(f"ğŸ“š æœ€ç»ˆä½¿ç”¨çš„å‚è€ƒæ–‡çŒ®refç¼–å·: {[c.get('ref_id') for c in used_citations]}")
                logger.info(f"ğŸ“š æœ€ç»ˆä½¿ç”¨çš„å‚è€ƒæ–‡çŒ®retrievalç¼–å·: {[c.get('retrieval_id') for c in used_citations]}")
                
                # æ„é€ å®Œæ•´çš„answer_dataï¼ˆåªåŒ…å«å®é™…ä½¿ç”¨çš„citationsï¼Œä½¿ç”¨è¿ç»­çš„IDç¼–å·ï¼‰
                answer_data = {
                    "answer": final_answer_text.strip(),  # ä½¿ç”¨æ›¿æ¢åçš„ç­”æ¡ˆæ–‡æœ¬
                    "citations": used_citations  # ä½¿ç”¨é‡æ–°ç¼–å·çš„citationsï¼ˆIDä¸º1, 2, 3...ï¼Œä½†ä¿ç•™ref_idå’Œretrieval_idå­—æ®µï¼‰
                }
                
                yield {
                    "type": "answer_complete",
                    "answer_data": answer_data
                }
                citations_sent = True
                
        except Exception as e:
            logger.debug(f"[DEBUG] Error in streaming answer: {e}")
            import traceback
            traceback.print_exc()
            yield {
                "type": "answer_error",
                "content": f"ç”Ÿæˆç­”æ¡ˆæ—¶å‡ºé”™: {str(e)}"
            }
    
    def generate_answer_with_citations(self, question: str, retrieval_results: List[Dict]) -> Dict:
        """ç”Ÿæˆå¸¦å¼•ç”¨çš„ç­”æ¡ˆï¼ˆéæµå¼ç‰ˆæœ¬ï¼Œä¿ç•™ç”¨äºå…¼å®¹ï¼‰"""
        try:
            # å‡†å¤‡æ¥æºå†…å®¹
            sources_content = self.create_sources_content_for_citation(retrieval_results)
            
            logger.debug(f"[DEBUG] Generating answer with citations for question: {question[:100]}...")
            logger.debug(f"[DEBUG] Sources content length: {len(sources_content)}")
            
            messages = [
                {
                    "role": "user",
                    "content": self.citation_prompt.format(
                        question=question,
                        sources_content=sources_content
                    )
                }
            ]
            
            response = self.client.chat.completions.create(
                model=self.model_name,
                messages=messages,
                temperature=0.5,
                max_tokens=4096,
                stream=False,
                extra_body={"enable_thinking": False}  # æ˜ç¡®ç¦ç”¨thinkingæ¨¡å¼ï¼ˆéæµå¼è°ƒç”¨ï¼‰
            )
            
            content = response.choices[0].message.content
            logger.debug(f"[DEBUG] Raw answer generation response: {content}")
            
            # å°è¯•è§£æJSON
            try:
                # æ¸…ç†å¯èƒ½çš„markdownæ ¼å¼
                if content.startswith("```json"):
                    content = content.replace("```json", "").replace("```", "").strip()
                elif content.startswith("```"):
                    content = content.replace("```", "").strip()
                
                result = json.loads(content)
                logger.debug(f"[DEBUG] Parsed answer result: {result}")
                return result
            except json.JSONDecodeError as e:
                logger.debug(f"[DEBUG] JSON parse failed: {e}")
                # å¦‚æœä¸æ˜¯æœ‰æ•ˆJSONï¼Œå°è¯•æå–
                return self._extract_answer_from_text(content)
                
        except Exception as e:
            logger.debug(f"[DEBUG] Error generating answer: {e}")
            import traceback
            traceback.print_exc()
            return {
                "answer": f"ç”Ÿæˆç­”æ¡ˆæ—¶å‡ºé”™: {str(e)}",
                "citations": []
            }

    def _extract_judgment_from_text(self, text: str) -> Dict:
        """ä»æ–‡æœ¬ä¸­æå–åˆ¤æ–­ç»“æœï¼ˆä»æ ¼å¼åŒ–æ–‡æœ¬ä¸­æå–ï¼‰"""
        logger.debug(f"[DEBUG] Extracting judgment from text: {text[:300]}...")
        
        import re
        
        # é»˜è®¤å€¼
        can_answer = True  # é»˜è®¤å‡è®¾å¯ä»¥å›ç­”
        confidence = 0.8
        reason = "æ£€ç´¢å†…å®¹ç›¸å…³"
        missing_info = ""
        
        # æå– **èƒ½å¦å›ç­”**: å¯ä»¥/ä¸èƒ½
        can_answer_match = re.search(r'\*\*èƒ½å¦å›ç­”\*\*:\s*(å¯ä»¥|ä¸èƒ½)', text)
        if can_answer_match:
            can_answer = can_answer_match.group(1) == "å¯ä»¥"
        else:
            # å¤‡ç”¨ï¼šä»JSONä¸­æå–ï¼ˆå¦‚æœæœ‰ï¼‰
            can_answer_json = re.search(r'"can_answer"\s*:\s*(true|false)', text, re.IGNORECASE)
            if can_answer_json:
                can_answer = can_answer_json.group(1).lower() == 'true'
            else:
                # ä»æ–‡æœ¬æ¨æ–­
                can_answer = "å¯ä»¥" in text or "èƒ½å¤Ÿ" in text
        
        # æå– **ç½®ä¿¡åº¦**: 0.XX
        confidence_match = re.search(r'\*\*ç½®ä¿¡åº¦\*\*:\s*(0\.\d+|1\.0|0|1)', text)
        if confidence_match:
            try:
                confidence = float(confidence_match.group(1))
            except ValueError:
                pass
        else:
            # å¤‡ç”¨ï¼šä»JSONä¸­æå–ï¼ˆå¦‚æœæœ‰ï¼‰
            confidence_json = re.search(r'"confidence"\s*:\s*(0\.\d+|1\.0|0|1)', text)
            if confidence_json:
                try:
                    confidence = float(confidence_json.group(1))
                except ValueError:
                    pass
        
        # æå– **åˆ†æ**: åçš„å†…å®¹ä½œä¸ºreason
        analysis_match = re.search(r'\*\*åˆ†æ\*\*:\s*(.+?)(?:\n\n|\{|$)', text, re.DOTALL)
        if analysis_match:
            reason = analysis_match.group(1).strip()
        else:
            # å¤‡ç”¨ï¼šä»JSONä¸­æå–ï¼ˆå¦‚æœæœ‰ï¼‰
            reason_json = re.search(r'"reason"\s*:\s*"([^"]+)"', text, re.DOTALL)
            if reason_json:
                reason = reason_json.group(1).strip()
            else:
                # ä½¿ç”¨æ•´ä¸ªæ–‡æœ¬ï¼ˆæ¸…ç†åï¼‰
                cleaned_text = re.sub(r'```json|```|\{.*\}', '', text, flags=re.DOTALL)
                cleaned_text = re.sub(r'\*\*èƒ½å¦å›ç­”\*\*:.*?\n', '', cleaned_text)
                cleaned_text = re.sub(r'\*\*ç½®ä¿¡åº¦\*\*:.*?\n', '', cleaned_text)
                cleaned_text = re.sub(r'\*\*åˆ†æ\*\*:\s*', '', cleaned_text)
                reason = cleaned_text.strip()[:300]
        
        # å°è¯•æå– missing_infoï¼ˆå¦‚æœæœ‰JSONï¼‰
        missing_match = re.search(r'"missing_info"\s*:\s*"([^"]+)"', text, re.DOTALL)
        if missing_match:
            missing_info = missing_match.group(1).strip()
        
        result = {
            "can_answer": can_answer,
            "confidence": confidence,
            "reason": reason,
            "missing_info": missing_info
        }
        logger.debug(f"[DEBUG] Extracted judgment result: {result}")
        return result

    def _extract_answer_from_text(self, text: str) -> Dict:
        """ä»æ–‡æœ¬ä¸­æå–ç­”æ¡ˆå’Œå¼•ç”¨"""
        logger.debug(f"[DEBUG] Extracting answer from text: {text[:200]}...")
        
        try:
            # å°è¯•ä»æ–‡æœ¬ä¸­æå–JSONéƒ¨åˆ†
            # æŸ¥æ‰¾å¯èƒ½çš„JSONå—
            start_markers = ['{', '{\n', '```json\n{', '```\n{']
            end_markers = ['}', '\n}', '}\n```', '}\n']
            
            for start_marker in start_markers:
                start_idx = text.find(start_marker)
                if start_idx != -1:
                    for end_marker in end_markers:
                        end_idx = text.rfind(end_marker)
                        if end_idx > start_idx:
                            json_text = text[start_idx:end_idx + len(end_marker.rstrip('\n'))]
                            try:
                                result = json.loads(json_text)
                                logger.debug(f"[DEBUG] Successfully extracted JSON: {result}")
                                return result
                            except json.JSONDecodeError:
                                continue
            
            # å¦‚æœæ— æ³•æå–JSONï¼Œåˆ›å»ºä¸€ä¸ªç®€å•çš„ç­”æ¡ˆç»“æ„
            logger.debug(f"[DEBUG] Could not extract JSON, creating simple answer structure")
            return {
                "answer": text.strip(),
                "citations": []
            }
            
        except Exception as e:
            logger.debug(f"[DEBUG] Error in _extract_answer_from_text: {e}")
            return {
                "answer": text.strip() if text else "æ— æ³•ç”Ÿæˆç­”æ¡ˆ",
                "citations": []
            }

    def format_final_answer(self, answer_data: Dict) -> str:
        """æ ¼å¼åŒ–æœ€ç»ˆç­”æ¡ˆï¼Œæ”¯æŒå¯ç‚¹å‡»çš„å¼•ç”¨å±•å¼€"""
        # ç¡®ä¿answer_dataæ˜¯å­—å…¸
        if isinstance(answer_data, str):
            try:
                answer_data = json.loads(answer_data)
            except json.JSONDecodeError:
                return answer_data  # å¦‚æœä¸æ˜¯JSONï¼Œç›´æ¥è¿”å›åŸå§‹å­—ç¬¦ä¸²
        
        answer = answer_data.get("answer", "")
        citations = answer_data.get("citations", [])
        
        # å¦‚æœæ²¡æœ‰answerå­—æ®µï¼Œå¯èƒ½æ•´ä¸ªç­”æ¡ˆå°±åœ¨answer_dataä¸­
        if not answer and isinstance(answer_data, str):
            answer = answer_data
        
        # æ„å»ºæœ€ç»ˆç­”æ¡ˆ
        final_answer = answer + "\n\n"
        
        if citations:
            final_answer += "å‚è€ƒæ–‡çŒ®: \n\n"
            for citation in citations:
                citation_id = citation.get("id", "")
                title = citation.get("title", "")
                preview = citation.get("preview", "")
                full_content = citation.get("full_content", "")
                similarity = citation.get("similarity", 0.0)
                
                # ç”Ÿæˆå¯ç‚¹å‡»çš„å¼•ç”¨æ ¼å¼
                # ä½¿ç”¨HTMLæ ¼å¼æ”¯æŒç‚¹å‡»å±•å¼€
                clickable_preview = f'<span class="citation-preview" data-full-content="{full_content}" data-citation-id="{citation_id}">{preview}</span>'
                final_answer += f"[{citation_id}] {title} {clickable_preview}\n"
        
        return final_answer

    def format_final_answer_plain(self, answer_data: Dict) -> str:
        """æ ¼å¼åŒ–æœ€ç»ˆç­”æ¡ˆï¼ˆçº¯æ–‡æœ¬ç‰ˆæœ¬ï¼‰"""
        logger.debug(f"[DEBUG] format_final_answer_plain called with: {answer_data}")
        
        # ç¡®ä¿answer_dataæ˜¯å­—å…¸
        if isinstance(answer_data, str):
            try:
                answer_data = json.loads(answer_data)
            except json.JSONDecodeError:
                return answer_data  # å¦‚æœä¸æ˜¯JSONï¼Œç›´æ¥è¿”å›åŸå§‹å­—ç¬¦ä¸²
        
        answer = answer_data.get("answer", "")
        citations = answer_data.get("citations", [])
        
        # å¦‚æœæ²¡æœ‰answerå­—æ®µï¼Œå¯èƒ½æ•´ä¸ªç­”æ¡ˆå°±åœ¨answer_dataä¸­
        if not answer and isinstance(answer_data, str):
            answer = answer_data
        
        logger.debug(f"[DEBUG] Extracted answer: {answer}")
        logger.debug(f"[DEBUG] Extracted citations: {citations}")
        
        # æ„å»ºæœ€ç»ˆç­”æ¡ˆ
        final_answer = answer
        
        if citations and len(citations) > 0:
            final_answer += "\n\nå‚è€ƒæ–‡çŒ®:\n"
            for citation in citations:
                citation_id = citation.get("id", "")
                title = citation.get("title", "")
                full_content = citation.get("full_content", "")
                
                # æˆªå–å‰30ä¸ªå­—ä½œä¸ºé¢„è§ˆ
                preview = full_content[:30] if len(full_content) > 30 else full_content
                
                # æ ¼å¼ï¼š[ç¼–å·] æ–‡ç« é¢˜ç›®ï¼ˆæ¢è¡Œï¼‰å‚è€ƒç‰‡æ®µï¼ˆå‰30å­—ï¼‰
                final_answer += f"[{citation_id}] {title}\n{preview}\n"
        
        logger.debug(f"[DEBUG] Final formatted answer: {final_answer}")
        return final_answer

    def parse_retrieval_results(self, retrieval_output: str) -> List[Dict]:
        """è§£ææ£€ç´¢ç»“æœ"""
        results = []
        
        try:
            # ç¡®ä¿è¾“å…¥æ˜¯å­—ç¬¦ä¸²
            if not isinstance(retrieval_output, str):
                retrieval_output = str(retrieval_output)
            
            logger.debug(f"[DEBUG] Parsing retrieval output: {retrieval_output[:200]}...")
            
            # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼è§£ææ£€ç´¢ç»“æœ
            pattern = r'\[(\d+)\] Document: (.*?)\nSimilarity: (.*?)\nContent: (.*?)(?=\n\[|\n---|\Z)'
            matches = re.findall(pattern, retrieval_output, re.DOTALL)
            
            logger.debug(f"[DEBUG] Found {len(matches)} matches")
            
            for match in matches:
                index, title, similarity, content = match
                
                # å¤„ç†å†…å®¹ï¼Œç”Ÿæˆé¢„è§ˆå’Œå®Œæ•´å†…å®¹
                content = content.strip()
                preview = content[:30] + "..." if len(content) > 30 else content
                
                results.append({
                    "id": int(index),
                    "title": title.strip(),
                    "similarity": float(similarity.strip()),
                    "content": content,
                    "preview": preview,
                    "full_content": content
                })
            
            logger.debug(f"[DEBUG] Parsed {len(results)} retrieval results")
            return results
            
        except Exception as e:
            logger.debug(f"[DEBUG] Error parsing retrieval results: {str(e)}")
            import traceback
            traceback.print_exc()
            return []

    def create_sources_content_for_citation(self, retrieval_results: List[Dict]) -> str:
        """
        ä¸ºå¼•ç”¨ç”Ÿæˆåˆ›å»ºæ¥æºå†…å®¹å­—ç¬¦ä¸²ï¼ˆä½¿ç”¨retrieval_XXç¼–å·ï¼‰
        
        æ£€ç´¢ç»“æœç¼–å·ï¼šretrieval_01, retrieval_02, ..., retrieval_10, retrieval_11, ...ï¼ˆæŒ‰å®é™…æ•°é‡ï¼‰
        """
        sources_content = ""
        MAX_CONTENT_LENGTH = 800  # æ¯æ¡æ£€ç´¢ç»“æœæœ€å¤š800å­—
        
        for i in range(len(retrieval_results)):
            result = retrieval_results[i]
            # æ ¹æ®å®é™…æ•°é‡å†³å®šç¼–å·æ ¼å¼ï¼š1-9ç”¨01-09ï¼Œ10ä»¥ä¸Šç”¨å®é™…æ•°å­—
            if i + 1 < 10:
                retrieval_id = f"retrieval_{i+1:02d}"  # retrieval_01, retrieval_02, ..., retrieval_09
            else:
                retrieval_id = f"retrieval_{i+1}"  # retrieval_10, retrieval_11, ...
            title = result.get("title", f"æ–‡æ¡£{i+1}")
            content = result.get("content", "")
            similarity = result.get("similarity", 0.0)
            
            # é™åˆ¶å†…å®¹é•¿åº¦ï¼Œå‡å°‘prompt tokens
            if len(content) > MAX_CONTENT_LENGTH:
                content = content[:MAX_CONTENT_LENGTH] + "..."
            
            # ç¡®ä¿ç»“æœæœ‰æ­£ç¡®çš„retrieval_id
            result["retrieval_id"] = retrieval_id
            
            # ç¡®ä¿æœ‰é¢„è§ˆæ–‡æœ¬
            if "preview" not in result:
                result["preview"] = content[:30] + "..." if len(content) > 30 else content
            
            sources_content += f"[{retrieval_id}] æ ‡é¢˜: {title}\n"
            sources_content += f"å†…å®¹: {content}\n\n"  # ç§»é™¤ç›¸ä¼¼åº¦ï¼Œå‡å°‘tokens
        
        logger.info(f"ğŸ“ å‡†å¤‡ç­”æ¡ˆç”Ÿæˆå†…å®¹: {len(sources_content)} å­—ç¬¦, {len(retrieval_results)} æ¡æ£€ç´¢ç»“æœ")
        return sources_content