import json
import re
import logging
from typing import Dict, List, Optional, Tuple
from openai import OpenAI
import os

# é…ç½®æ—¥å¿—
logger = logging.getLogger(__name__)


class AnswerJudgmentSystem:
    """ç­”æ¡ˆåˆ¤æ–­å’Œå¼•ç”¨ç³»ç»Ÿ"""
    
    def __init__(self):
        self.api_key = os.environ.get("API_KEY")
        self.api_base = os.environ.get("API_BASE")
        self.model_name = os.environ.get("LLM_MODEL", "")
        self.summary_model_name = os.environ.get("SUMMARY_MODEL_NAME", "")
        
        self.client = OpenAI(
            api_key=self.api_key,
            base_url=self.api_base,
        )
        
        # åˆ¤æ–­æ£€ç´¢å†…å®¹æ˜¯å¦èƒ½å›ç­”é—®é¢˜çš„æç¤ºè¯ï¼ˆå‹å¥½æ ¼å¼è¾“å‡ºï¼‰
        self.judgment_prompt = """è¯„ä¼°æ£€ç´¢å†…å®¹æ˜¯å¦èƒ½å›ç­”ç”¨æˆ·é—®é¢˜ã€‚

é—®é¢˜: {question}

æ£€ç´¢å†…å®¹:
{retrieval_content}

è¯·æŒ‰ä»¥ä¸‹æ ¼å¼è¾“å‡ºè¯„ä¼°ç»“æœï¼š

**èƒ½å¦å›ç­”**: å¯ä»¥/ä¸èƒ½
**ç½®ä¿¡åº¦**: 0.XX (0.0-1.0ä¹‹é—´çš„æ•°å­—)
**åˆ†æ**: ç®€è¦åˆ†ææ£€ç´¢å†…å®¹æ˜¯å¦èƒ½å¤Ÿå›ç­”é—®é¢˜åŠåŸå› ï¼Œå­—æ•°é™åˆ¶åœ¨300å­—ä»¥å†…ã€‚

æ³¨æ„ï¼šè¾“å‡ºå®Œ"åˆ†æ"å†…å®¹åï¼Œç«‹å³åœæ­¢ã€‚ä¸è¦è¾“å‡ºä»»ä½•JSONæ ¼å¼çš„å†…å®¹ã€‚"""

        # ç”Ÿæˆå¸¦å¼•ç”¨ç­”æ¡ˆçš„æç¤ºè¯
        self.citation_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ä¸´åºŠåŒ»ç”Ÿã€‚è¯·åŸºäºæä¾›çš„æ£€ç´¢å†…å®¹å›ç­”ç”¨æˆ·é—®é¢˜ï¼Œå¹¶ä¸¥æ ¼æŒ‰ç…§å­¦æœ¯è®ºæ–‡æ ¼å¼æ·»åŠ å¼•ç”¨ã€‚

ç”¨æˆ·é—®é¢˜: {question}

æ£€ç´¢å†…å®¹åŠæ¥æº:
{sources_content}

è¦æ±‚ï¼š
When providing final answers, you MUST use academic citation format:
1. Include numbered citations [1][2][3] in your answer text
2. Provide a reference list at the end with format: "Document Title\\n relevant part"
3. Make citations clickable by using the proper format
4. make sure the reference not the same

**CRITICAL: å‚è€ƒæ–‡çŒ®ç¼–å·è§„åˆ™ï¼ˆå¿…é¡»ä¸¥æ ¼éµå®ˆï¼‰**
- ç¼–å·å¿…é¡»ä»1å¼€å§‹ï¼Œä¸¥æ ¼æŒ‰ç…§åœ¨ç­”æ¡ˆä¸­é¦–æ¬¡å‡ºç°çš„é¡ºåºåˆ†é…
- ç¬¬ä¸€ä¸ªå¼•ç”¨çš„å†…å®¹å¿…é¡»æ ‡è®°ä¸º[1]ï¼Œç¬¬äºŒä¸ªä¸º[2]ï¼Œç¬¬ä¸‰ä¸ªä¸º[3]ï¼Œä»¥æ­¤ç±»æ¨
- ç»å¯¹ç¦æ­¢è·³è·ƒç¼–å·ï¼Œå¦‚[1][2][14]æˆ–[1][3][5]ç­‰
- ç¼–å·å¿…é¡»è¿ç»­é€’å¢ï¼š1, 2, 3, 4, 5...
- åœ¨citationsæ•°ç»„ä¸­ï¼Œidå­—æ®µä¹Ÿå¿…é¡»å¯¹åº”ï¼š1, 2, 3, 4, 5...

**é‡è¦ï¼šè¯·åˆ†ä¸¤ä¸ªé˜¶æ®µç”Ÿæˆå†…å®¹**
ç¬¬ä¸€é˜¶æ®µï¼šå…ˆç”Ÿæˆå®Œæ•´çš„ç­”æ¡ˆå†…å®¹ï¼ˆåŒ…å«å¼•ç”¨æ ‡å·ï¼‰
ç¬¬äºŒé˜¶æ®µï¼šç«‹å³ç”Ÿæˆå‚è€ƒæ–‡çŒ®åˆ—è¡¨

Exampleï¼ˆæ­£ç¡®ç¤ºä¾‹ï¼‰:
ç¬¬ä¸€é˜¶æ®µ - ç­”æ¡ˆå†…å®¹:
"ç³–å°¿ç—…ä¸»è¦åˆ†ä¸º1å‹ç³–å°¿ç—…[1]å’Œ2å‹ç³–å°¿ç—…[2]ï¼Œè¿˜æœ‰å¦Šå¨ ç³–å°¿ç—…ç­‰ç‰¹æ®Šç±»å‹[3]ã€‚æ ¹æ®æœ€æ–°æŒ‡å—ï¼Œ1å‹ç³–å°¿ç—…éœ€è¦ç»ˆèº«èƒ°å²›ç´ æ²»ç–—[1]ï¼Œè€Œ2å‹ç³–å°¿ç—…å¯ä»¥é€šè¿‡ç”Ÿæ´»æ–¹å¼å¹²é¢„å’Œè¯ç‰©æ²»ç–—æ¥æ§åˆ¶[2]ã€‚å¦Šå¨ ç³–å°¿ç—…éœ€è¦ç‰¹æ®Šçš„è¡€ç³–ç®¡ç†ç­–ç•¥[3]ã€‚"

ç¬¬äºŒé˜¶æ®µ - å‚è€ƒæ–‡çŒ®:
"å‚è€ƒæ–‡çŒ®:

[1] ç³–å°¿ç—…è¯Šç–—æŒ‡å—.pdf 
è¦ç‚¹ï¼šÂ·é¥®é£Ÿè´¨é‡å’Œèƒ½é‡æ§åˆ¶æ˜¯è¡€ç³–ç®¡ç†çš„åŸºç¡€...

[2] å†…åˆ†æ³Œå­¦æ•™æ.pdf 
è¯¥æ®µè½æ€»ç»“äº†ç”Ÿæ´»æ–¹å¼åŒ»å­¦åœ¨2å‹ç³–å°¿ç—…ï¼ˆT2Dï¼‰åŠç³–å°¿ç—…å‰æœŸé¢„é˜²å’Œç®¡ç†ä¸­çš„å…³é”®ä½œç”¨...

[3] å¦Šå¨ æœŸç–¾ç—…æ‰‹å†Œ.pdf 
è¡Œä¸ºä¸ç”Ÿæ´»æ–¹å¼å¹²é¢„çš„åŸåˆ™..."

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼å›ç­”ï¼ˆæ³¨æ„JSONæ ¼å¼çš„æ­£ç¡®æ€§ï¼‰ï¼š
{{
    "answer": "å®Œæ•´çš„ç­”æ¡ˆå†…å®¹ï¼ŒåŒ…å«å¼•ç”¨æ ‡å·[1][2][3]ç­‰ï¼ˆç¼–å·å¿…é¡»ä»1å¼€å§‹ä¾æ¬¡é€’å¢ï¼‰",
    "citations": [
        {{
            "id": 1,
            "title": "æ–‡æ¡£æ ‡é¢˜",
            "preview": "å¼•ç”¨å†…å®¹å‰30å­—...",
            "full_content": "å®Œæ•´çš„å¼•ç”¨å†…å®¹"
        }},
        {{
            "id": 2,
            "title": "æ–‡æ¡£æ ‡é¢˜",
            "preview": "å¼•ç”¨å†…å®¹å‰30å­—...",
            "full_content": "å®Œæ•´çš„å¼•ç”¨å†…å®¹"
        }}
    ]
}}"""

    def judge_retrieval_sufficiency_stream(self, question: str, retrieval_content: str):
        """æµå¼åˆ¤æ–­æ£€ç´¢å†…å®¹æ˜¯å¦è¶³å¤Ÿå›ç­”é—®é¢˜ - å®æ—¶æµå¼è¾“å‡ºåˆ¤æ–­æ–‡æœ¬"""
        try:
            # ç¡®ä¿è¾“å…¥éƒ½æ˜¯å­—ç¬¦ä¸²
            if not isinstance(question, str):
                question = str(question)
            if not isinstance(retrieval_content, str):
                retrieval_content = str(retrieval_content)
                
            logger.debug(f"[DEBUG] Judging retrieval sufficiency (streaming) for question: {question[:100]}...")
            logger.debug(f"[DEBUG] Retrieval content length: {len(retrieval_content)}")
            
            messages = [
                {
                    "role": "user", 
                    "content": self.judgment_prompt.format(
                        question=question,
                        retrieval_content=retrieval_content
                    )
                }
            ]
            
            # ä½¿ç”¨æµå¼API
            response = self.client.chat.completions.create(
                model=self.model_name,
                messages=messages,
                temperature=0.1,
                max_tokens=500,
                stream=True,
                extra_body={"enable_thinking": False}
            )
            
            # æµå¼æ¥æ”¶å¹¶å®æ—¶å‘é€å†…å®¹
            accumulated_content = ""
            judgment_text = ""
            
            for chunk in response:
                if chunk.choices[0].delta.content:
                    chunk_text = chunk.choices[0].delta.content
                    accumulated_content += chunk_text
                    judgment_text += chunk_text
                    
                    # å®æ—¶å‘é€åˆ¤æ–­æ–‡æœ¬ç‰‡æ®µ
                    yield {
                        "type": "judgment_chunk",
                        "content": chunk_text,
                        "accumulated": judgment_text
                    }
            
            logger.debug(f"[DEBUG] Judgment text complete (length={len(judgment_text)})")
            
            # æµå¼å®Œæˆåï¼Œç›´æ¥ä»æ–‡æœ¬ä¸­æå–åˆ¤æ–­ç»“æœï¼ˆä¸å†ä¾èµ–JSONï¼‰
            try:
                result = self._extract_judgment_from_text(accumulated_content)
                logger.debug(f"[DEBUG] Extracted judgment from text: {result}")
                yield {
                    "type": "judgment_complete",
                    "judgment": result
                }
            except Exception as e:
                logger.debug(f"[DEBUG] Error extracting judgment: {e}")
                # è¿”å›é»˜è®¤å€¼
                yield {
                    "type": "judgment_complete",
                    "judgment": {"can_answer": True, "confidence": 0.5, "reason": "æ— æ³•è§£æåˆ¤æ–­ç»“æœ"}
                }
                
        except Exception as e:
            logger.debug(f"[DEBUG] Error in streaming judgment: {e}")
            import traceback
            traceback.print_exc()
            
            yield {
                "type": "judgment_error",
                "content": f"åˆ¤æ–­è¿‡ç¨‹å‡ºé”™: {str(e)}"
            }

    def judge_retrieval_sufficiency(self, question: str, retrieval_content: str) -> Dict:
        """åˆ¤æ–­æ£€ç´¢å†…å®¹æ˜¯å¦è¶³å¤Ÿå›ç­”é—®é¢˜ - ä½¿ç”¨æµå¼è¾“å‡ºåŠ é€Ÿ"""
        try:
            # ç¡®ä¿è¾“å…¥éƒ½æ˜¯å­—ç¬¦ä¸²
            if not isinstance(question, str):
                question = str(question)
            if not isinstance(retrieval_content, str):
                retrieval_content = str(retrieval_content)
                
            logger.debug(f"[DEBUG] Judging retrieval sufficiency (streaming) for question: {question[:100]}...")
            logger.debug(f"[DEBUG] Retrieval content length: {len(retrieval_content)}")
            
            messages = [
                {
                    "role": "user", 
                    "content": self.judgment_prompt.format(
                        question=question,
                        retrieval_content=retrieval_content
                    )
                }
            ]
            
            # ä½¿ç”¨æµå¼APIåŠ é€Ÿå“åº”ï¼Œé™åˆ¶tokenæ•°ä»¥åŠ å¿«åˆ¤æ–­é€Ÿåº¦
            response = self.client.chat.completions.create(
                model=self.model_name,
                messages=messages,
                temperature=0.1,  # é™ä½æ¸©åº¦ï¼Œæé«˜ç¡®å®šæ€§å’Œé€Ÿåº¦
                max_tokens=500,  # å¤§å¹…å‡å°‘tokenæ•°ï¼ŒåŠ å¿«å“åº”ï¼ˆåˆ¤æ–­åªéœ€è¦ç®€çŸ­çš„JSONï¼‰
                stream=True,  # æ”¹ä¸ºæµå¼
                extra_body={"enable_thinking": False}
            )
            
            # æµå¼æ¥æ”¶å¹¶ç´¯ç§¯å†…å®¹ï¼Œå°è¯•æå‰æ£€æµ‹å®Œæ•´JSON
            content = ""
            early_parsed = False
            for chunk in response:
                if chunk.choices[0].delta.content:
                    content += chunk.choices[0].delta.content
                    
                    # å°è¯•æå‰æ£€æµ‹å®Œæ•´çš„JSONå¯¹è±¡ï¼ˆå½“æ£€æµ‹åˆ° }} æ—¶ï¼‰
                    if not early_parsed and content.count('}') >= 2:
                        try:
                            # å°è¯•è§£æå½“å‰ç´¯ç§¯çš„å†…å®¹
                            temp_content = content.strip()
                            if temp_content.startswith("```json"):
                                temp_content = temp_content.replace("```json", "").strip()
                            elif temp_content.startswith("```"):
                                temp_content = temp_content.replace("```", "").strip()
                            
                            # å°è¯•æ‰¾åˆ°ç¬¬ä¸€ä¸ªå®Œæ•´çš„JSONå¯¹è±¡
                            if '{' in temp_content and '}' in temp_content:
                                start = temp_content.find('{')
                                # ç®€å•çš„æ‹¬å·åŒ¹é…
                                depth = 0
                                end = -1
                                for i in range(start, len(temp_content)):
                                    if temp_content[i] == '{':
                                        depth += 1
                                    elif temp_content[i] == '}':
                                        depth -= 1
                                        if depth == 0:
                                            end = i + 1
                                            break
                                
                                if end > 0:
                                    json_str = temp_content[start:end]
                                    result = json.loads(json_str)
                                    # æ£€æŸ¥æ˜¯å¦åŒ…å«å¿…è¦å­—æ®µ
                                    if 'can_answer' in result and 'confidence' in result:
                                        logger.debug(f"[DEBUG] Early parsed judgment result from stream")
                                        early_parsed = True
                                        # ç»§ç»­æ¥æ”¶å‰©ä½™å†…å®¹ï¼Œä½†ä¸å†å°è¯•è§£æ
                                        break
                        except:
                            pass  # ç»§ç»­æ¥æ”¶æ›´å¤šå†…å®¹
            
            logger.debug(f"[DEBUG] Judgment response (streamed, length={len(content)}): {content[:200]}...")
            
            # å°è¯•è§£æJSONï¼ˆæ”¯æŒmarkdownåŒ…è£¹çš„JSONï¼‰
            try:
                # é¦–å…ˆå°è¯•ç›´æ¥è§£æ
                result = json.loads(content)
                logger.debug(f"[DEBUG] Parsed judgment result: {result}")
                return result
            except json.JSONDecodeError:
                # å°è¯•æ¸…ç†markdownæ ‡è®°åå†è§£æ
                cleaned_content = content.strip()
                if cleaned_content.startswith("```json"):
                    cleaned_content = cleaned_content.replace("```json", "").replace("```", "").strip()
                elif cleaned_content.startswith("```"):
                    cleaned_content = cleaned_content.replace("```", "").strip()
                
                try:
                    result = json.loads(cleaned_content)
                    logger.debug(f"[DEBUG] Parsed judgment result after cleaning: {result}")
                    return result
                except json.JSONDecodeError:
                    # å¦‚æœä»ç„¶æ— æ³•è§£æï¼Œå°è¯•ä»æ–‡æœ¬ä¸­æå–
                    logger.debug(f"[DEBUG] Failed to parse JSON even after cleaning, extracting from text")
                    return self._extract_judgment_from_text(content)
                
        except Exception as e:
            logger.debug(f"[DEBUG] Error in judgment: {e}")
            import traceback
            traceback.print_exc()
            return {
                "can_answer": False,
                "confidence": 0.0,
                "reason": f"åˆ¤æ–­è¿‡ç¨‹å‡ºé”™: {str(e)}",
                "missing_info": "æ— æ³•è¯„ä¼°"
            }

    def _pre_generate_citations(self, question: str, retrieval_results: List[Dict]) -> List[Dict]:
        """
        é¢„ç”Ÿæˆå‚è€ƒæ–‡çŒ®åˆ—è¡¨
        
        Args:
            question: ç”¨æˆ·é—®é¢˜
            retrieval_results: æ£€ç´¢ç»“æœåˆ—è¡¨
            
        Returns:
            List[Dict]: é¢„ç”Ÿæˆçš„å‚è€ƒæ–‡çŒ®åˆ—è¡¨
        """
        try:
            # åŸºäºæ£€ç´¢ç»“æœç›´æ¥æ„é€ å‚è€ƒæ–‡çŒ®
            citations = []
            for i, result in enumerate(retrieval_results[:10], 1):  # æœ€å¤š10ä¸ªå‚è€ƒæ–‡çŒ®
                citation = {
                    "id": i,
                    "title": result.get("title", f"æ–‡æ¡£ {i}"),
                    "preview": result.get("content", "")[:30] + "..." if len(result.get("content", "")) > 30 else result.get("content", ""),
                    "full_content": result.get("content", "")
                }
                citations.append(citation)
            
            logger.debug(f"[DEBUG] é¢„ç”Ÿæˆå‚è€ƒæ–‡çŒ®å®Œæˆ: {len(citations)} items")
            return citations
            
        except Exception as e:
            logger.debug(f"[DEBUG] é¢„ç”Ÿæˆå‚è€ƒæ–‡çŒ®å¤±è´¥: {e}")
            return []

    def generate_answer_with_citations_stream(self, question: str, retrieval_results: List[Dict]):
        """
        æµå¼ç”Ÿæˆå¸¦å¼•ç”¨çš„ç­”æ¡ˆ - é¢„ç”Ÿæˆå‚è€ƒæ–‡çŒ®ä¼˜åŒ–ç‰ˆæœ¬
        
        ä¼˜åŒ–ç­–ç•¥ï¼š
        1. å…ˆåŸºäºæ£€ç´¢ç»“æœé¢„ç”Ÿæˆå‚è€ƒæ–‡çŒ®
        2. ç„¶åæµå¼ç”Ÿæˆç­”æ¡ˆæ–‡æœ¬
        3. ç­”æ¡ˆç”Ÿæˆå®Œæˆåç«‹å³æ˜¾ç¤ºé¢„ç”Ÿæˆçš„å‚è€ƒæ–‡çŒ®
        """
        try:
            # å‡†å¤‡æ¥æºå†…å®¹
            sources_content = self.create_sources_content_for_citation(retrieval_results)
            
            logger.debug(f"[DEBUG] Streaming answer generation for question: {question[:100]}...")
            logger.debug(f"[DEBUG] Sources content length: {len(sources_content)}")
            
            # ç¬¬ä¸€æ­¥ï¼šé¢„ç”Ÿæˆå‚è€ƒæ–‡çŒ®
            logger.debug(f"[DEBUG] é¢„ç”Ÿæˆå‚è€ƒæ–‡çŒ®...")
            pre_generated_citations = self._pre_generate_citations(question, retrieval_results)
            
            # ç¬¬äºŒæ­¥ï¼šæµå¼ç”Ÿæˆç­”æ¡ˆæ–‡æœ¬ï¼ˆä¸åŒ…å«å‚è€ƒæ–‡çŒ®ï¼‰
            answer_prompt = f"""**è¯·æ ¹æ®ä»¥ä¸‹æ£€ç´¢å†…å®¹å›ç­”ç”¨æˆ·é—®é¢˜ï¼š**

**æç¤ºï¼š** åœ¨å›ç­”ä¸­å¿…é¡»ä¸¥æ ¼éµå¾ªå¼•ç”¨ç¼–å·è§„åˆ™ã€‚**ä¸è¦ç”Ÿæˆå‚è€ƒæ–‡çŒ®åˆ—è¡¨**ï¼Œä»…éœ€æŒ‰é¡ºåºæ ‡è®°å¼•ç”¨ç¼–å·ã€‚

## å¼•ç”¨ç¼–å·è§„åˆ™ï¼ˆä¸¥æ ¼éµå®ˆï¼‰ï¼š

* æ¯æ¬¡åœ¨ç­”æ¡ˆä¸­å¼•ç”¨æŸç¯‡æ–‡çŒ®æ—¶ï¼Œå¿…é¡»æ ¹æ®å¼•ç”¨é¡ºåºè¿›è¡Œç¼–å·ã€‚
* ç¬¬ä¸€æ¬¡å¼•ç”¨æŸä¸ªæ–‡çŒ®æ—¶ï¼Œæ ‡è®°ä¸º[1]ã€‚
* ç¬¬äºŒæ¬¡å¼•ç”¨åŒä¸€æ–‡çŒ®æ—¶ï¼Œæ ‡è®°ä¸º[2]ã€‚
* ç¬¬ä¸‰æ¬¡å¼•ç”¨åŒä¸€æ–‡çŒ®æ—¶ï¼Œæ ‡è®°ä¸º[3]ã€‚
* ç¼–å·ä»1å¼€å§‹ï¼Œä¾ç…§åœ¨ç­”æ¡ˆä¸­çš„å¼•ç”¨å…ˆåé¡ºåºé€’å¢ã€‚

**æ³¨æ„ï¼š**

* è¯·ç¡®ä¿ç¼–å·ä»ç¬¬ä¸€ä¸ªå¼•ç”¨å¼€å§‹é€’å¢ï¼Œä¸è¦è·³å·ã€‚
* é”™è¯¯ç¤ºä¾‹ï¼š
  â€œæ‚£è€…ç¬¦åˆDKA[3]...åº”è¡¥æ¶²[1]...â€ â† ç¬¬ä¸€ä¸ªå¼•ç”¨åº”æ ‡è®°ä¸º[1]ï¼Œç¬¬äºŒä¸ªä¸º[2]ã€‚
  æ­£ç¡®ç¤ºä¾‹ï¼š
  â€œæ‚£è€…ç¬¦åˆDKA[1]...åº”è¡¥æ¶²[2]...â€ â† æ­£ç¡®æŒ‰å¼•ç”¨é¡ºåºæ ‡è®°ã€‚
---
## æ£€ç´¢å†…å®¹ï¼š{sources_content}

## é—®é¢˜å¦‚ä¸‹ï¼š"""
            
            messages = [
                {
                    "role": "system",
                    "content": answer_prompt
                },
                {
                    "role": "user",
                    "content": question
                }
            ]
            
            # ä½¿ç”¨æµå¼APIï¼ˆä¼˜åŒ–é¦–tokenå“åº”é€Ÿåº¦ï¼‰
            import time
            api_start_time = time.time()
            logger.info(f"ğŸš€ å¼€å§‹è°ƒç”¨ç­”æ¡ˆç”ŸæˆAPI (æ¨¡å‹: {self.summary_model_name})")
            
            response = self.client.chat.completions.create(
                model=self.summary_model_name,
                messages=messages,
                temperature=0.1,  # æä½temperatureç¡®ä¿ä¸¥æ ¼éµå®ˆè§„åˆ™
                max_tokens=2048,  # è¿›ä¸€æ­¥å‡å°‘max_tokensåŠ å¿«é¦–token (4096â†’2048)
                stream=True  # å¯ç”¨æµå¼
            )
            
            accumulated_content = ""
            answer_text = ""
            last_yield_length = 0  # è®°å½•ä¸Šæ¬¡å‘é€çš„ä½ç½®
            citations_sent = False  # æ ‡è®°æ˜¯å¦å·²å‘é€citations
            first_token_received = False  # æ ‡è®°é¦–token
            
            # ç®€åŒ–çš„æµå¼ç”Ÿæˆé€»è¾‘
            for chunk in response:
                if chunk.choices[0].delta.content:
                    content_piece = chunk.choices[0].delta.content
                    
                    # è®°å½•é¦–tokenæ—¶é—´
                    if not first_token_received:
                        first_token_time = time.time() - api_start_time
                        logger.info(f"âš¡ æ”¶åˆ°é¦–ä¸ªtokenï¼Œè€—æ—¶: {first_token_time:.2f}ç§’")
                        first_token_received = True
                    
                    accumulated_content += content_piece
                    answer_text += content_piece
                    
                    # å‘é€ç­”æ¡ˆç‰‡æ®µ
                    if len(answer_text) > last_yield_length:
                        new_content = answer_text[last_yield_length:]
                        last_yield_length = len(answer_text)
                        
                        if new_content:
                            yield {
                                "type": "answer_chunk",
                                "content": new_content,
                            }
            
            # æµå¼å®Œæˆåï¼Œè¿‡æ»¤å¹¶å‘é€å®é™…ä½¿ç”¨çš„å‚è€ƒæ–‡çŒ®
            logger.debug(f"[DEBUG] Stream completed, answer length: {len(answer_text)}")
            
            if not citations_sent and pre_generated_citations:
                # æå–ç­”æ¡ˆä¸­å®é™…ä½¿ç”¨çš„å¼•ç”¨ç¼–å·
                import re
                citation_numbers = set()
                # åŒ¹é… [æ•°å­—] æ ¼å¼
                for match in re.finditer(r'\[(\d+)\]', answer_text):
                    citation_numbers.add(int(match.group(1)))
                
                # åªä¿ç•™ç­”æ¡ˆä¸­å®é™…å¼•ç”¨çš„æ–‡çŒ®
                used_citations = []
                for citation in pre_generated_citations:
                    if citation['id'] in citation_numbers:
                        used_citations.append(citation)
                
                # æŒ‰å¼•ç”¨ç¼–å·æ’åº
                used_citations.sort(key=lambda x: x['id'])
                
                logger.info(f"ğŸ“š ç­”æ¡ˆä¸­ä½¿ç”¨äº† {len(used_citations)}/{len(pre_generated_citations)} ä¸ªå‚è€ƒæ–‡çŒ®: {sorted(citation_numbers)}")
                
                # æ£€æŸ¥ç¼–å·æ˜¯å¦è¿ç»­
                if used_citations:
                    citation_ids = [c['id'] for c in used_citations]
                    expected_ids = list(range(1, len(citation_ids) + 1))
                    if citation_ids != expected_ids:
                        logger.warning(f"âš ï¸ å¼•ç”¨ç¼–å·ä¸è¿ç»­ï¼é¢„æœŸ: {expected_ids}, å®é™…: {citation_ids}")
                
                # æ„é€ å®Œæ•´çš„answer_dataï¼ˆåªåŒ…å«å®é™…ä½¿ç”¨çš„citationsï¼‰
                answer_data = {
                    "answer": answer_text.strip(),
                    "citations": used_citations
                }
                
                yield {
                    "type": "answer_complete",
                    "answer_data": answer_data
                }
                citations_sent = True
                
        except Exception as e:
            logger.debug(f"[DEBUG] Error in streaming answer: {e}")
            import traceback
            traceback.print_exc()
            yield {
                "type": "answer_error",
                "content": f"ç”Ÿæˆç­”æ¡ˆæ—¶å‡ºé”™: {str(e)}"
            }
    
    def generate_answer_with_citations(self, question: str, retrieval_results: List[Dict]) -> Dict:
        """ç”Ÿæˆå¸¦å¼•ç”¨çš„ç­”æ¡ˆï¼ˆéæµå¼ç‰ˆæœ¬ï¼Œä¿ç•™ç”¨äºå…¼å®¹ï¼‰"""
        try:
            # å‡†å¤‡æ¥æºå†…å®¹
            sources_content = self.create_sources_content_for_citation(retrieval_results)
            
            logger.debug(f"[DEBUG] Generating answer with citations for question: {question[:100]}...")
            logger.debug(f"[DEBUG] Sources content length: {len(sources_content)}")
            
            messages = [
                {
                    "role": "user",
                    "content": self.citation_prompt.format(
                        question=question,
                        sources_content=sources_content
                    )
                }
            ]
            
            response = self.client.chat.completions.create(
                model=self.model_name,
                messages=messages,
                temperature=0.5,
                max_tokens=4096,
                stream=False,
                extra_body={"enable_thinking": False}  # æ˜ç¡®ç¦ç”¨thinkingæ¨¡å¼ï¼ˆéæµå¼è°ƒç”¨ï¼‰
            )
            
            content = response.choices[0].message.content
            logger.debug(f"[DEBUG] Raw answer generation response: {content}")
            
            # å°è¯•è§£æJSON
            try:
                # æ¸…ç†å¯èƒ½çš„markdownæ ¼å¼
                if content.startswith("```json"):
                    content = content.replace("```json", "").replace("```", "").strip()
                elif content.startswith("```"):
                    content = content.replace("```", "").strip()
                
                result = json.loads(content)
                logger.debug(f"[DEBUG] Parsed answer result: {result}")
                return result
            except json.JSONDecodeError as e:
                logger.debug(f"[DEBUG] JSON parse failed: {e}")
                # å¦‚æœä¸æ˜¯æœ‰æ•ˆJSONï¼Œå°è¯•æå–
                return self._extract_answer_from_text(content)
                
        except Exception as e:
            logger.debug(f"[DEBUG] Error generating answer: {e}")
            import traceback
            traceback.print_exc()
            return {
                "answer": f"ç”Ÿæˆç­”æ¡ˆæ—¶å‡ºé”™: {str(e)}",
                "citations": []
            }

    def _extract_judgment_from_text(self, text: str) -> Dict:
        """ä»æ–‡æœ¬ä¸­æå–åˆ¤æ–­ç»“æœï¼ˆä»æ ¼å¼åŒ–æ–‡æœ¬ä¸­æå–ï¼‰"""
        logger.debug(f"[DEBUG] Extracting judgment from text: {text[:300]}...")
        
        import re
        
        # é»˜è®¤å€¼
        can_answer = True  # é»˜è®¤å‡è®¾å¯ä»¥å›ç­”
        confidence = 0.8
        reason = "æ£€ç´¢å†…å®¹ç›¸å…³"
        missing_info = ""
        
        # æå– **èƒ½å¦å›ç­”**: å¯ä»¥/ä¸èƒ½
        can_answer_match = re.search(r'\*\*èƒ½å¦å›ç­”\*\*:\s*(å¯ä»¥|ä¸èƒ½)', text)
        if can_answer_match:
            can_answer = can_answer_match.group(1) == "å¯ä»¥"
        else:
            # å¤‡ç”¨ï¼šä»JSONä¸­æå–ï¼ˆå¦‚æœæœ‰ï¼‰
            can_answer_json = re.search(r'"can_answer"\s*:\s*(true|false)', text, re.IGNORECASE)
            if can_answer_json:
                can_answer = can_answer_json.group(1).lower() == 'true'
            else:
                # ä»æ–‡æœ¬æ¨æ–­
                can_answer = "å¯ä»¥" in text or "èƒ½å¤Ÿ" in text
        
        # æå– **ç½®ä¿¡åº¦**: 0.XX
        confidence_match = re.search(r'\*\*ç½®ä¿¡åº¦\*\*:\s*(0\.\d+|1\.0|0|1)', text)
        if confidence_match:
            try:
                confidence = float(confidence_match.group(1))
            except ValueError:
                pass
        else:
            # å¤‡ç”¨ï¼šä»JSONä¸­æå–ï¼ˆå¦‚æœæœ‰ï¼‰
            confidence_json = re.search(r'"confidence"\s*:\s*(0\.\d+|1\.0|0|1)', text)
            if confidence_json:
                try:
                    confidence = float(confidence_json.group(1))
                except ValueError:
                    pass
        
        # æå– **åˆ†æ**: åçš„å†…å®¹ä½œä¸ºreason
        analysis_match = re.search(r'\*\*åˆ†æ\*\*:\s*(.+?)(?:\n\n|\{|$)', text, re.DOTALL)
        if analysis_match:
            reason = analysis_match.group(1).strip()
        else:
            # å¤‡ç”¨ï¼šä»JSONä¸­æå–ï¼ˆå¦‚æœæœ‰ï¼‰
            reason_json = re.search(r'"reason"\s*:\s*"([^"]+)"', text, re.DOTALL)
            if reason_json:
                reason = reason_json.group(1).strip()
            else:
                # ä½¿ç”¨æ•´ä¸ªæ–‡æœ¬ï¼ˆæ¸…ç†åï¼‰
                cleaned_text = re.sub(r'```json|```|\{.*\}', '', text, flags=re.DOTALL)
                cleaned_text = re.sub(r'\*\*èƒ½å¦å›ç­”\*\*:.*?\n', '', cleaned_text)
                cleaned_text = re.sub(r'\*\*ç½®ä¿¡åº¦\*\*:.*?\n', '', cleaned_text)
                cleaned_text = re.sub(r'\*\*åˆ†æ\*\*:\s*', '', cleaned_text)
                reason = cleaned_text.strip()[:300]
        
        # å°è¯•æå– missing_infoï¼ˆå¦‚æœæœ‰JSONï¼‰
        missing_match = re.search(r'"missing_info"\s*:\s*"([^"]+)"', text, re.DOTALL)
        if missing_match:
            missing_info = missing_match.group(1).strip()
        
        result = {
            "can_answer": can_answer,
            "confidence": confidence,
            "reason": reason,
            "missing_info": missing_info
        }
        logger.debug(f"[DEBUG] Extracted judgment result: {result}")
        return result

    def _extract_answer_from_text(self, text: str) -> Dict:
        """ä»æ–‡æœ¬ä¸­æå–ç­”æ¡ˆå’Œå¼•ç”¨"""
        logger.debug(f"[DEBUG] Extracting answer from text: {text[:200]}...")
        
        try:
            # å°è¯•ä»æ–‡æœ¬ä¸­æå–JSONéƒ¨åˆ†
            # æŸ¥æ‰¾å¯èƒ½çš„JSONå—
            start_markers = ['{', '{\n', '```json\n{', '```\n{']
            end_markers = ['}', '\n}', '}\n```', '}\n']
            
            for start_marker in start_markers:
                start_idx = text.find(start_marker)
                if start_idx != -1:
                    for end_marker in end_markers:
                        end_idx = text.rfind(end_marker)
                        if end_idx > start_idx:
                            json_text = text[start_idx:end_idx + len(end_marker.rstrip('\n'))]
                            try:
                                result = json.loads(json_text)
                                logger.debug(f"[DEBUG] Successfully extracted JSON: {result}")
                                return result
                            except json.JSONDecodeError:
                                continue
            
            # å¦‚æœæ— æ³•æå–JSONï¼Œåˆ›å»ºä¸€ä¸ªç®€å•çš„ç­”æ¡ˆç»“æ„
            logger.debug(f"[DEBUG] Could not extract JSON, creating simple answer structure")
            return {
                "answer": text.strip(),
                "citations": []
            }
            
        except Exception as e:
            logger.debug(f"[DEBUG] Error in _extract_answer_from_text: {e}")
            return {
                "answer": text.strip() if text else "æ— æ³•ç”Ÿæˆç­”æ¡ˆ",
                "citations": []
            }

    def format_final_answer(self, answer_data: Dict) -> str:
        """æ ¼å¼åŒ–æœ€ç»ˆç­”æ¡ˆï¼Œæ”¯æŒå¯ç‚¹å‡»çš„å¼•ç”¨å±•å¼€"""
        # ç¡®ä¿answer_dataæ˜¯å­—å…¸
        if isinstance(answer_data, str):
            try:
                answer_data = json.loads(answer_data)
            except json.JSONDecodeError:
                return answer_data  # å¦‚æœä¸æ˜¯JSONï¼Œç›´æ¥è¿”å›åŸå§‹å­—ç¬¦ä¸²
        
        answer = answer_data.get("answer", "")
        citations = answer_data.get("citations", [])
        
        # å¦‚æœæ²¡æœ‰answerå­—æ®µï¼Œå¯èƒ½æ•´ä¸ªç­”æ¡ˆå°±åœ¨answer_dataä¸­
        if not answer and isinstance(answer_data, str):
            answer = answer_data
        
        # æ„å»ºæœ€ç»ˆç­”æ¡ˆ
        final_answer = answer + "\n\n"
        
        if citations:
            final_answer += "å‚è€ƒæ–‡çŒ®: \n\n"
            for citation in citations:
                citation_id = citation.get("id", "")
                title = citation.get("title", "")
                preview = citation.get("preview", "")
                full_content = citation.get("full_content", "")
                similarity = citation.get("similarity", 0.0)
                
                # ç”Ÿæˆå¯ç‚¹å‡»çš„å¼•ç”¨æ ¼å¼
                # ä½¿ç”¨HTMLæ ¼å¼æ”¯æŒç‚¹å‡»å±•å¼€
                clickable_preview = f'<span class="citation-preview" data-full-content="{full_content}" data-citation-id="{citation_id}">{preview}</span>'
                final_answer += f"[{citation_id}] {title} {clickable_preview}\n"
        
        return final_answer

    def format_final_answer_plain(self, answer_data: Dict) -> str:
        """æ ¼å¼åŒ–æœ€ç»ˆç­”æ¡ˆï¼ˆçº¯æ–‡æœ¬ç‰ˆæœ¬ï¼‰"""
        logger.debug(f"[DEBUG] format_final_answer_plain called with: {answer_data}")
        
        # ç¡®ä¿answer_dataæ˜¯å­—å…¸
        if isinstance(answer_data, str):
            try:
                answer_data = json.loads(answer_data)
            except json.JSONDecodeError:
                return answer_data  # å¦‚æœä¸æ˜¯JSONï¼Œç›´æ¥è¿”å›åŸå§‹å­—ç¬¦ä¸²
        
        answer = answer_data.get("answer", "")
        citations = answer_data.get("citations", [])
        
        # å¦‚æœæ²¡æœ‰answerå­—æ®µï¼Œå¯èƒ½æ•´ä¸ªç­”æ¡ˆå°±åœ¨answer_dataä¸­
        if not answer and isinstance(answer_data, str):
            answer = answer_data
        
        logger.debug(f"[DEBUG] Extracted answer: {answer}")
        logger.debug(f"[DEBUG] Extracted citations: {citations}")
        
        # æ„å»ºæœ€ç»ˆç­”æ¡ˆ
        final_answer = answer
        
        if citations and len(citations) > 0:
            final_answer += "\n\nå‚è€ƒæ–‡çŒ®:\n"
            for citation in citations:
                citation_id = citation.get("id", "")
                title = citation.get("title", "")
                full_content = citation.get("full_content", "")
                
                # æˆªå–å‰30ä¸ªå­—ä½œä¸ºé¢„è§ˆ
                preview = full_content[:30] if len(full_content) > 30 else full_content
                
                # æ ¼å¼ï¼š[ç¼–å·] æ–‡ç« é¢˜ç›®ï¼ˆæ¢è¡Œï¼‰å‚è€ƒç‰‡æ®µï¼ˆå‰30å­—ï¼‰
                final_answer += f"[{citation_id}] {title}\n{preview}\n"
        
        logger.debug(f"[DEBUG] Final formatted answer: {final_answer}")
        return final_answer

    def parse_retrieval_results(self, retrieval_output: str) -> List[Dict]:
        """è§£ææ£€ç´¢ç»“æœ"""
        results = []
        
        try:
            # ç¡®ä¿è¾“å…¥æ˜¯å­—ç¬¦ä¸²
            if not isinstance(retrieval_output, str):
                retrieval_output = str(retrieval_output)
            
            logger.debug(f"[DEBUG] Parsing retrieval output: {retrieval_output[:200]}...")
            
            # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼è§£ææ£€ç´¢ç»“æœ
            pattern = r'\[(\d+)\] Document: (.*?)\nSimilarity: (.*?)\nContent: (.*?)(?=\n\[|\n---|\Z)'
            matches = re.findall(pattern, retrieval_output, re.DOTALL)
            
            logger.debug(f"[DEBUG] Found {len(matches)} matches")
            
            for match in matches:
                index, title, similarity, content = match
                
                # å¤„ç†å†…å®¹ï¼Œç”Ÿæˆé¢„è§ˆå’Œå®Œæ•´å†…å®¹
                content = content.strip()
                preview = content[:30] + "..." if len(content) > 30 else content
                
                results.append({
                    "id": int(index),
                    "title": title.strip(),
                    "similarity": float(similarity.strip()),
                    "content": content,
                    "preview": preview,
                    "full_content": content
                })
            
            logger.debug(f"[DEBUG] Parsed {len(results)} retrieval results")
            return results
            
        except Exception as e:
            logger.debug(f"[DEBUG] Error parsing retrieval results: {str(e)}")
            import traceback
            traceback.print_exc()
            return []

    def create_sources_content_for_citation(self, retrieval_results: List[Dict]) -> str:
        """ä¸ºå¼•ç”¨ç”Ÿæˆåˆ›å»ºæ¥æºå†…å®¹å­—ç¬¦ä¸²ï¼ˆä¼˜åŒ–ï¼šé™åˆ¶å†…å®¹é•¿åº¦ï¼‰"""
        sources_content = ""
        MAX_CONTENT_LENGTH = 800  # æ¯æ¡æ£€ç´¢ç»“æœæœ€å¤š800å­—
        
        for i, result in enumerate(retrieval_results, 1):
            title = result.get("title", f"æ–‡æ¡£{i}")
            content = result.get("content", "")
            similarity = result.get("similarity", 0.0)
            
            # é™åˆ¶å†…å®¹é•¿åº¦ï¼Œå‡å°‘prompt tokens
            if len(content) > MAX_CONTENT_LENGTH:
                content = content[:MAX_CONTENT_LENGTH] + "..."
            
            # ç¡®ä¿ç»“æœæœ‰æ­£ç¡®çš„IDï¼ˆç”¨äºå¼•ç”¨ï¼‰
            if "id" not in result:
                result["id"] = i
            
            # ç¡®ä¿æœ‰é¢„è§ˆæ–‡æœ¬
            if "preview" not in result:
                result["preview"] = content[:30] + "..." if len(content) > 30 else content
            
            sources_content += f"[{i}] æ ‡é¢˜: {title}\n"
            sources_content += f"å†…å®¹: {content}\n\n"  # ç§»é™¤ç›¸ä¼¼åº¦ï¼Œå‡å°‘tokens
        
        logger.info(f"ğŸ“ å‡†å¤‡ç­”æ¡ˆç”Ÿæˆå†…å®¹: {len(sources_content)} å­—ç¬¦, {len(retrieval_results)} æ¡æ£€ç´¢ç»“æœ")
        return sources_content